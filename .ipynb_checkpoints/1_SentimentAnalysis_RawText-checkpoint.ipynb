{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### READ ME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this script, we perform a basic Sentiment Analysis of the answers to the consultation questions 1, 4, 5, and 8, using Python's Vader module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Imports and Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up working directory\n",
    "\n",
    "cwd = os.chdir('/Users/alessia/Documents/DataScience/NLP_Project/Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in data (note header is spread over two rows)\n",
    "\n",
    "cons0_df = pd.read_excel(\"The CensusCopy.xlsx\",  header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Transform Data\n",
    "\n",
    "3.1. Combine the headers - now in two rows - into one unique row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Explore data\n",
    "\n",
    "cons0_df.head(3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1110, 50)\n"
     ]
    }
   ],
   "source": [
    "print( cons0_df.values.shape )  # (1110, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Row 1: \n",
    "\n",
    "# propagate non-null values forward, so that if a cell contains a NaN, the cell gets the value of the cell before\n",
    "\n",
    "row1 = cons0_df.ffill(1).values[:1, :]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "(1, 50)\n",
      "[['Respondent ID'\n",
      "  '9. Are there any other issues that you believe we should be taking into account?']]\n"
     ]
    }
   ],
   "source": [
    "# Checks\n",
    "print(row1.ndim)\n",
    "print(row1.shape)          # (1,50)\n",
    "print(row1[:, [0, -1]])    # print first and last values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Row 2: \n",
    "\n",
    "# replace NaN with empty cell (otherwise they will be float object, we want a list of only strings)\n",
    "\n",
    "row2 = cons0_df.fillna('').values[1:2, :] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "2\n",
      "(1, 50)\n",
      "[['' 'Open-Ended Response']]\n"
     ]
    }
   ],
   "source": [
    "#Checks\n",
    "print(type(row2))\n",
    "print(row2.ndim)\n",
    "print(row2.shape)  # (1,50)\n",
    "print(row2[:, [0, -1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combine row1 and row2 into one unique \"header\" row\n",
    "\n",
    "header_row = row1 + row2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2. Reconstruct the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save header_row as DataFrame\n",
    "header_row_df = pd.DataFrame(header_row)\n",
    "\n",
    "# Save all other rows as dataframe\n",
    "data_values_df = pd.DataFrame(cons0_df.values[2:, :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Append the two together\n",
    "cons1_df = header_row_df.append(data_values_df,  \n",
    "                                ignore_index=True\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make first row as header\n",
    "cons1_df.columns = cons1_df.iloc[0]\n",
    "\n",
    "# Drop the first row (which is now redundant)\n",
    "cons1_df = cons1_df.drop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reset index \n",
    "cons1_df = cons1_df.reset_index(drop=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Respondent ID' 'Collector ID' 'Start Date' 'End Date' 'IP Address'\n",
      " 'Email Address' 'First Name' 'Last Name']\n",
      "[ '9. Are there any other issues that you believe we should be taking into account?Open-Ended Response']\n"
     ]
    }
   ],
   "source": [
    "# Checks\n",
    "print(cons1_df.columns.values[:8])\n",
    "print(cons1_df.columns.values[-1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Sentiment Analysis of questions 1, 4, 5 and 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1. Define function to calculate polarity score for the answers in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define function to calculate polarity score for the answers in our dataset\n",
    "\n",
    "def get_sentiment_score(data, col_ind) :\n",
    "    \"\"\" Return list of polarity scores for values in the specified column \"\"\"\n",
    "    \n",
    "    # import key modules\n",
    "    from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "    analyser = SentimentIntensityAnalyzer()\n",
    "    \n",
    "    # empty list collector of scores\n",
    "    sentiment_bag = []\n",
    "    \n",
    "    for answer in data.iloc[:, col_ind] :\n",
    "        \n",
    "        # no answer was provided, return NA\n",
    "        if pd.isnull(answer) : \n",
    "            sentiment_bag.append(np.nan)\n",
    "            \n",
    "        else :\n",
    "            sentiment_bag.append(analyser.polarity_scores(answer)['compound'])\n",
    "    \n",
    "    return(sentiment_bag)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2. Calculate Sentiment Score for answers to relevant questions: Q1, Q4, Q5, Q8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get column index of questions\n",
    "\n",
    "idx_Q1 = cons1_df.columns.get_loc(str([col for col in cons1_df if 'census methods' in str(col)][0]))\n",
    "idx_Q4 = cons1_df.columns.get_loc(str([col for col in cons1_df if '4. 1. ' in str(col)][0]))\n",
    "idx_Q5 = cons1_df.columns.get_loc(str([col for col in cons1_df if '5. 1.' in str(col)][0]))\n",
    "idx_Q8 = cons1_df.columns.get_loc(str([col for col in cons1_df if '8.' in str(col)][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39, 43, 45, 48)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checks\n",
    "idx_Q1, idx_Q4, idx_Q5, idx_Q8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alessia/anaconda3/lib/python3.6/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "# Calculate and save the Sentiment Score as new columns in the dataset\n",
    "\n",
    "cons1_df.loc[:, ('Q1_Sentiment')] = get_sentiment_score(cons1_df, idx_Q1)\n",
    "cons1_df.loc[:, ('Q4_Sentiment')] = get_sentiment_score(cons1_df, idx_Q4)\n",
    "cons1_df.loc[:, ('Q5_Sentiment')] = get_sentiment_score(cons1_df, idx_Q5)\n",
    "cons1_df.loc[:, ('Q8_Sentiment')] = get_sentiment_score(cons1_df, idx_Q8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Take a look at the result\n",
    "cons1_df.iloc[:, [idx_Q1, -4, idx_Q4, -3, idx_Q5, -2, idx_Q8, -1]];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1_Sentiment</th>\n",
       "      <th>Q4_Sentiment</th>\n",
       "      <th>Q5_Sentiment</th>\n",
       "      <th>Q8_Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>736.000000</td>\n",
       "      <td>523.000000</td>\n",
       "      <td>396.000000</td>\n",
       "      <td>490.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.388333</td>\n",
       "      <td>0.073410</td>\n",
       "      <td>0.338060</td>\n",
       "      <td>0.092375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.523643</td>\n",
       "      <td>0.515057</td>\n",
       "      <td>0.425649</td>\n",
       "      <td>0.575458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.981700</td>\n",
       "      <td>-0.983000</td>\n",
       "      <td>-0.904200</td>\n",
       "      <td>-0.969100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.318200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.361200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.493900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.440400</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.866425</td>\n",
       "      <td>0.440400</td>\n",
       "      <td>0.690275</td>\n",
       "      <td>0.633900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.999800</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.995400</td>\n",
       "      <td>0.998800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0      Q1_Sentiment  Q4_Sentiment  Q5_Sentiment  Q8_Sentiment\n",
       "count    736.000000    523.000000    396.000000    490.000000\n",
       "mean       0.388333      0.073410      0.338060      0.092375\n",
       "std        0.523643      0.515057      0.425649      0.575458\n",
       "min       -0.981700     -0.983000     -0.904200     -0.969100\n",
       "25%        0.000000     -0.318200      0.000000     -0.361200\n",
       "50%        0.493900      0.000000      0.440400      0.000000\n",
       "75%        0.866425      0.440400      0.690275      0.633900\n",
       "max        0.999800      0.999900      0.995400      0.998800"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary satistics\n",
    "cons1_df.iloc[:, [idx_Q1, -4, idx_Q4, -3, idx_Q5, -2, idx_Q8, -1]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save dataset\n",
    "\n",
    "cons1_df.to_csv('/Users/alessia/Documents/DataScience/NLP_Project/Outputs/cons1_SA_df.csv', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
