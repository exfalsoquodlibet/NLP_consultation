{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run 'Improving_functions.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = pd.Series([\"\", \n",
    "                  'I love double-cream ice-cream', \n",
    "                  'I hate fudge! But, I like caramel', \n",
    "                  'Pseudo-science, I -care',\n",
    "                  'You are lying to me: You ate much more than that!',\n",
    "                  \"Why should I have done that?\",\n",
    "                  \"I don't want to hear. Leave me dreaming.\",\n",
    "                  \"Are you still drinking? That's unbelievable! You shouldn't!!!\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text\n",
      "0                                                   \n",
      "1                      I love double-cream ice-cream\n",
      "2                  I hate fudge. But, I like caramel\n",
      "3                            Pseudo-science. I -care\n",
      "4              You are lying to me abou what you ate\n",
      "5            I don't want to hear. Leave me dreaming\n",
      "6  Are you still drinking? That's unbelievable! Y...\n"
     ]
    }
   ],
   "source": [
    "dummy_df = pd.DataFrame(text)\n",
    "dummy_df.columns = ['text']\n",
    "print(dummy_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                                     \n",
      "1                        I love double-cream ice-cream\n",
      "2                    I hate fudge. But, I like caramel\n",
      "3                              Pseudo-science. I -care\n",
      "4                You are lying to me abou what you ate\n",
      "5              I don't want to hear. Leave me dreaming\n",
      "6    Are you still drinking? That's unbelievable! Y...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(dummy_df['text'])\n",
    "dummy_df['t1_toksen'] = sent_tokenise_answer(dummy_df.iloc[:, 0])\n",
    "dummy_df['t2_tokwor'] = word_tokenise_answer(dummy_df.iloc[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                                   []\n",
      "1                      [I love double-cream ice-cream]\n",
      "2                 [I hate fudge., But, I like caramel]\n",
      "3                           [Pseudo-science., I -care]\n",
      "4              [You are lying to me abou what you ate]\n",
      "5           [I don't want to hear., Leave me dreaming]\n",
      "6    [Are you still drinking?, That's unbelievable!...\n",
      "Name: t1_toksen, dtype: object\n",
      "0                                                   []\n",
      "1                 [[i, love, double-cream, ice-cream]]\n",
      "2    [[i, hate, fudge, .], [but, ,, i, like, caramel]]\n",
      "3                    [[pseudo-science, .], [i, -care]]\n",
      "4    [[you, are, lying, to, me, abou, what, you, ate]]\n",
      "5    [[i, do, n't, want, to, hear, .], [leave, me, ...\n",
      "6    [[are, you, still, drinking, ?], [that, 's, un...\n",
      "Name: t2_tokwor, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(dummy_df['t1_toksen'])\n",
    "print(dummy_df['t2_tokwor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of sentence in the answer = 1\n",
      "No. of sentence in the answer = 2\n",
      "No. of sentence in the answer = 2\n",
      "No. of sentence in the answer = 1\n",
      "No. of sentence in the answer = 2\n",
      "No. of sentence in the answer = 3\n"
     ]
    }
   ],
   "source": [
    "dummy_df['t3_tokwor_bw'] = break_words(dummy_df['t2_tokwor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                                   []\n",
      "1                      [I love double-cream ice-cream]\n",
      "2                 [I hate fudge., But, I like caramel]\n",
      "3                           [Pseudo-science., I -care]\n",
      "4              [You are lying to me abou what you ate]\n",
      "5           [I don't want to hear., Leave me dreaming]\n",
      "6    [Are you still drinking?, That's unbelievable!...\n",
      "Name: t1_toksen, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                                                     \n",
       "1               [[i, love, double, cream, ice, cream]]\n",
       "2    [[i, hate, fudge, .], [but, ,, i, like, caramel]]\n",
       "3                    [[pseudo, science, .], [i, care]]\n",
       "4    [[you, are, lying, to, me, abou, what, you, ate]]\n",
       "5    [[i, do, n't, want, to, hear, .], [leave, me, ...\n",
       "6    [[are, you, still, drinking, ?], [that, 's, un...\n",
       "Name: t3_tokwor_bw, dtype: object"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dummy_df['t1_toksen'])\n",
    "dummy_df['t3_tokwor_bw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of sentence in the answer = 1\n",
      "No. of sentence in the answer = 2\n",
      "No. of sentence in the answer = 2\n",
      "No. of sentence in the answer = 1\n",
      "No. of sentence in the answer = 2\n",
      "No. of sentence in the answer = 3\n",
      "0                                                     \n",
      "1               [[i, love, double, cream, ice, cream]]\n",
      "2    [[i, hate, fudge, .], [but, ,, i, like, caramel]]\n",
      "3                    [[pseudo, science, .], [i, care]]\n",
      "4    [[you, are, lying, to, me, abou, what, you, ate]]\n",
      "5    [[i, do, not, want, to, hear, .], [leave, me, ...\n",
      "6    [[are, you, still, drinking, ?], [that, 's, un...\n",
      "Name: t4_tokwor_fn, dtype: object\n"
     ]
    }
   ],
   "source": [
    "dummy_df['t4_tokwor_fn'] = fix_neg_aux(dummy_df['t3_tokwor_bw'])\n",
    "print(dummy_df['t4_tokwor_fn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                                     \n",
      "1               [[i, love, double, cream, ice, cream]]\n",
      "2    [[i, hate, fudge, .], [but, ,, i, like, caramel]]\n",
      "3                    [[pseudo, science, .], [i, care]]\n",
      "4    [[you, are, lying, to, me, abou, what, you, ate]]\n",
      "5    [[i, do, n't, want, to, hear, .], [leave, me, ...\n",
      "Name: text2, dtype: object\n",
      "No. of sentence in the answer = 1\n",
      "No. of sentence in the answer = 2\n",
      "No. of sentence in the answer = 2\n",
      "No. of sentence in the answer = 1\n",
      "No. of sentence in the answer = 2\n",
      "0                                             \n",
      "1          [[love, double, cream, ice, cream]]\n",
      "2       [[hate, fudge, .], [,, like, caramel]]\n",
      "3               [[pseudo, science, .], [care]]\n",
      "4                         [[lying, abou, ate]]\n",
      "5    [[n't, want, hear, .], [leave, dreaming]]\n",
      "Name: text3, dtype: object\n"
     ]
    }
   ],
   "source": [
    "dummy_df['text3'] = remove_stopwords(dummy_df['text2'], stopwords_list=stopwords.words('english'))\n",
    "print(dummy_df['text3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummy_df['text4'] = POS_tagging(dummy_df['text2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of sentences (length of cell) = 0\n",
      "No. of sentences (length of cell) = 1\n",
      "No. of tuples (length of sent) = 6\n",
      "No. of sentences (length of cell) = 2\n",
      "No. of tuples (length of sent) = 4\n",
      "No. of tuples (length of sent) = 5\n",
      "No. of sentences (length of cell) = 2\n",
      "No. of tuples (length of sent) = 3\n",
      "No. of tuples (length of sent) = 2\n",
      "No. of sentences (length of cell) = 1\n",
      "No. of tuples (length of sent) = 9\n",
      "No. of sentences (length of cell) = 2\n",
      "No. of tuples (length of sent) = 7\n",
      "No. of tuples (length of sent) = 3\n"
     ]
    }
   ],
   "source": [
    "dummy_df['text5'] = lemmatise(dummy_df['text4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cons1_df = pd.read_csv(\"/Users/alessia/Documents/DataScience/NLP_Project/Outputs/cons1_lemmas_df.csv\", nrows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get column index of questions\n",
    "idx_Q1 = cons1_df.columns.get_loc(str([col for col in cons1_df if 'census methods' in str(col)][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cons1_df.loc[:, 'test1'] = sent_tokenise_answer(cons1_df.iloc[:,idx_Q1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "nan\n",
      "nan\n",
      "[0.0, -0.4585]\n",
      "[0.0, 0.3818, 0.0, 0.4404, 0.0, 0.0, 0.4404, 0.0, 0.8481, 0.7964, -0.1779, 0.0, 0.4404, 0.4404]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(result) for result in get_sentiment_score(cons1_df.iloc[:, test1_idx])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan, nan, nan, -0.22925000000000001, 0.25785714285714284]\n",
      "[nan, nan, nan, -0.22925000000000001, 0.19089999999999999]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alessia/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py:4016: RuntimeWarning: Invalid value encountered in median\n",
      "  r = func(a, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print([np.mean(np.array(result)) for result in get_sentiment_score(cons1_df.iloc[:,test1_idx])])\n",
    "print([np.median(np.array(result)) for result in get_sentiment_score(cons1_df.iloc[:,test1_idx])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
