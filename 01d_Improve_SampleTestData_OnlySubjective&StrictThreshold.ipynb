{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improving Sample for Test Data: a stricter polarity threshold keeping only subjective sentences\n",
    "\n",
    "Here we create a new verion of the sample for the test data that tries to improve the iter-rater reliabiliy agreements on the sentiment of the answers/texts, by only keeping those sentences that, in each answer/text, are classified as subjective (TextBlob) and have a polarity score that meets a stricter threshold (|0.3|).\n",
    "\n",
    "Workflow:\n",
    "\n",
    "1. Only keep those sentences that, in each answer/text, are subjective\n",
    "2. Calculate polarity score for each sentence in each text using Vader\n",
    "3. Eliminate all those scores that do not meet the (stricter) threshold for positivity/nagativity\n",
    "4. Calculate mean polarity score for the text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Imports and Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Set up working directory\n",
    "cwd = os.chdir('/Users/alessia/Documents/DataScience/NLP_Project/Outputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in data using literal_eval and converers\n",
    "testdata_sample = pd.read_csv(\"sa_q1_sample_testdata.csv\", converters=dict(VDR_SA_scores_sents=literal_eval, \n",
    "                                                                           TB_SA_score_sents = literal_eval, \n",
    "                                                                           subjty_score_sents = literal_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata_sample.dtypes;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fix the columns containing a mixture of strings and floats (NaN) due to pd.to_csv...\n",
    "\n",
    "testdata_sample['only_subj_VDR_scores'] = testdata_sample['only_subj_VDR_scores'].map(lambda x: literal_eval(x) if isinstance(x, str) else [x])\n",
    "\n",
    "testdata_sample['only_subj_TB_scores'] = testdata_sample['only_subj_TB_scores'].map(lambda x: literal_eval(x) if isinstance(x, str) else [x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Import basic NLP functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cwd = os.chdir('/Users/alessia/Documents/DataScience/textconsultations/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nlpfunctions', 'tutorial', 'README.md', '.git']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.listdir('nlpfunctions');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alessia/anaconda3/lib/python3.6/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "import nlpfunctions.basic_NLP_functions as b_nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Calculate stricter mean polarity score for the only-subjective texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Unnamed: 0.1', 'Unnamed: 0.1.1', 'Respondent ID',\n",
       "       'Q1_census_methods',\n",
       "       'Are you responding on behalf of an organisation, or as an individual?Response',\n",
       "       'PublicSector', 'PrivateSector', 'OtherSectors', 'sent_tok_text',\n",
       "       'VDR_SA_scores_sents', 'mean_VDR_SA_scores', 'VDR_polarity',\n",
       "       'TB_SA_score_sents', 'TB_mean_SA_score', 'TB_polarity',\n",
       "       'subjty_score_sents', 'Q1_only_subj_sents', 'only_subj_VDR_scores',\n",
       "       'only_subj_mean_VDR_score', 'only_subj_VDR_polarity',\n",
       "       'only_subj_TB_scores', 'only_subj_mean_TB_score',\n",
       "       'only_subj_TB_polarity', 'strict_VDR_SA_scores_sents',\n",
       "       'mean_strict_VDR_score', 'strict_VDR_polarity',\n",
       "       'only_strict_polarity_sents', 'strict_sents_TB_scores',\n",
       "       'strict_sent_mean_TB_score', 'strict_sent_TB_polarity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdata_sample.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentence-tokenise texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testdata_sample['subj_sent_tok_text'] = testdata_sample['Q1_only_subj_sents'].apply(lambda x: b_nlp.sent_tokenise_df(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove (i.e., assign NaN) to all those VDR polarity scores that do not meet the threshold. \n",
    "I.e., -0.3 <= score <= 0.3 are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    <class 'list'>\n",
       "1    <class 'list'>\n",
       "2    <class 'list'>\n",
       "3    <class 'list'>\n",
       "4    <class 'list'>\n",
       "Name: only_subj_VDR_scores, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdata_sample['only_subj_VDR_scores'].map(type)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testdata_sample['only_subj_strict_VDR_scores_sents'] = testdata_sample['only_subj_VDR_scores'].apply(lambda x: b_nlp.get_sentiment_stricter_threshold_df(x, polarity_threshold = 0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testdata_sample[['only_subj_strict_VDR_scores_sents', 'only_subj_VDR_scores', 'strict_VDR_SA_scores_sents']];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Re-calculate text's mean polarity score using VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alessia/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: RuntimeWarning: Mean of empty slice\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "testdata_sample['mean_only_subj_strict_VDR_score'] = testdata_sample['only_subj_strict_VDR_scores_sents'].apply(lambda x: np.nanmean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testdata_sample['only_subj_strict_VDR_polarity'] = testdata_sample['mean_only_subj_strict_VDR_score'].apply(lambda x: 'pos' if x > 0 else 'neg' if x < 0 else \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From each text, remove the sentences whose polarity score does not meet the stricter threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testdata_sample['only_subj_strict_polarity_sents'] = testdata_sample['subj_sent_tok_text'].apply(lambda x: b_nlp.keep_only_strict_polarity_sents_df(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check\n",
    "testdata_sample[['subj_sent_tok_text', \n",
    "                 'only_subj_strict_polarity_sents', \n",
    "                 'only_subj_strict_VDR_polarity', \n",
    "                 'mean_only_subj_strict_VDR_score', 'only_subj_strict_VDR_scores_sents']][:10];\n",
    "\n",
    "# Some negative sentences are not picked up correctly..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Re-Calculate TextBlob polarity score on strict polarity texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testdata_sample['only_subj_strict_sents_TB_scores'] = testdata_sample['only_subj_strict_polarity_sents'].apply(lambda x: b_nlp.get_textblob_sentiment_score_df(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alessia/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: RuntimeWarning: Mean of empty slice\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "testdata_sample['only_subj_strict_sent_mean_TB_score'] = testdata_sample['only_subj_strict_sents_TB_scores'].apply(lambda x: np.nanmean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testdata_sample['only_subj_strict_sent_TB_polarity'] = testdata_sample['only_subj_strict_sent_mean_TB_score'].apply(lambda x: 'pos' if x > 0 else 'neg' if x < 0 else \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Agreements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "102 texts go \"removed\", so our sample size is now 98 texts... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN: 0\n",
      "       102\n",
      "pos    63 \n",
      "neg    35 \n",
      "Name: only_subj_strict_VDR_polarity, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of NaN: {}\".format(testdata_sample['only_subj_strict_VDR_polarity'].isnull().sum()))\n",
    "print(testdata_sample['only_subj_strict_VDR_polarity'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Checks\n",
    "testdata_sample.head(3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>only_subj_strict_sent_TB_polarity</th>\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>only_subj_strict_VDR_polarity</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neg</th>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "only_subj_strict_sent_TB_polarity       neg  pos\n",
       "only_subj_strict_VDR_polarity                   \n",
       "                                   102  0    0  \n",
       "neg                                3    11   21 \n",
       "pos                                3    7    53 "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(testdata_sample['only_subj_strict_VDR_polarity'], testdata_sample['only_subj_strict_sent_TB_polarity'])\n",
    "# still many texts (21) that VADER classifies as negative while TB considers posiive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison between VDR polarity rating of (A&B) stricter threshold subjective texts vs. (B) stricter threshold text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>strict_VDR_polarity</th>\n",
       "      <th>neg</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>only_subj_strict_VDR_polarity</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>38</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neg</th>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos</th>\n",
       "      <td>9</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "strict_VDR_polarity            neg  pos\n",
       "only_subj_strict_VDR_polarity          \n",
       "                               38   29 \n",
       "neg                            25   10 \n",
       "pos                            9    54 "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(testdata_sample['only_subj_strict_VDR_polarity'], testdata_sample['strict_VDR_polarity'], )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison between VDR polarity rating of (A&B) stricter threshold subjective texts vs. (B) only subjective text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>only_subj_VDR_polarity</th>\n",
       "      <th>neg</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>only_subj_strict_VDR_polarity</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neg</th>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos</th>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "only_subj_VDR_polarity         neg  pos\n",
       "only_subj_strict_VDR_polarity          \n",
       "                               9    14 \n",
       "neg                            34   1  \n",
       "pos                            2    61 "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(testdata_sample['only_subj_strict_VDR_polarity'], testdata_sample['only_subj_VDR_polarity'], )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save data\n",
    "testdata_sample.to_csv(\"/Users/alessia/Documents/DataScience/NLP_Project/Outputs/sa_q1_sample_testdata.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
