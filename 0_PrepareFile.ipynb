{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### READ ME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this script, we prepare the data file for analysis by combining the headers (now sprad over two rows) in one unique row."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Imports and Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up working directory\n",
    "\n",
    "cwd = os.chdir('/Users/alessia/Documents/DataScience/NLP_Project/Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in data (note header is spread over two rows)\n",
    "\n",
    "cons0_df = pd.read_excel(\"The CensusCopy.xlsx\",  header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Transform Data\n",
    "\n",
    "3.1. Combine the headers - now in two rows - into one unique row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Explore data\n",
    "\n",
    "cons0_df.head(3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1110, 50)\n"
     ]
    }
   ],
   "source": [
    "print( cons0_df.values.shape )  # (1110, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Row 1: \n",
    "\n",
    "# propagate non-null values forward, so that if a cell contains a NaN, the cell gets the value of the cell before\n",
    "\n",
    "row1 = cons0_df.ffill(1).values[:1, :]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "(1, 50)\n",
      "[['Respondent ID'\n",
      "  '9. Are there any other issues that you believe we should be taking into account?']]\n"
     ]
    }
   ],
   "source": [
    "# Checks\n",
    "print(row1.ndim)\n",
    "print(row1.shape)          # (1,50)\n",
    "print(row1[:, [0, -1]])    # print first and last values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Row 2: \n",
    "\n",
    "# replace NaN with empty cell (otherwise they will be float object, we want a list of only strings)\n",
    "\n",
    "row2 = cons0_df.fillna('').values[1:2, :] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "2\n",
      "(1, 50)\n",
      "[['' 'Open-Ended Response']]\n"
     ]
    }
   ],
   "source": [
    "#Checks\n",
    "print(type(row2))\n",
    "print(row2.ndim)\n",
    "print(row2.shape)  # (1,50)\n",
    "print(row2[:, [0, -1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combine row1 and row2 into one unique \"header\" row\n",
    "\n",
    "header_row = row1 + row2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2. Reconstruct the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save header_row as DataFrame\n",
    "header_row_df = pd.DataFrame(header_row)\n",
    "\n",
    "# Save all other rows as dataframe\n",
    "data_values_df = pd.DataFrame(cons0_df.values[2:, :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Append the two together\n",
    "cons1_df = header_row_df.append(data_values_df,  \n",
    "                                ignore_index=True\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make first row as header\n",
    "cons1_df.columns = cons1_df.iloc[0]\n",
    "\n",
    "# Drop the first row (which is now redundant)\n",
    "cons1_df = cons1_df.drop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reset index \n",
    "cons1_df = cons1_df.reset_index(drop=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Respondent ID' 'Collector ID' 'Start Date' 'End Date' 'IP Address'\n",
      " 'Email Address' 'First Name' 'Last Name']\n",
      "[ '9. Are there any other issues that you believe we should be taking into account?Open-Ended Response']\n"
     ]
    }
   ],
   "source": [
    "# Checks\n",
    "print(cons1_df.columns.values[:8])\n",
    "print(cons1_df.columns.values[-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataset\n",
    "\n",
    "cons1_df.to_csv('/Users/alessia/Documents/DataScience/NLP_Project/Outputs/cons1_df.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
