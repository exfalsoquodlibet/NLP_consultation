{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### READ ME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this script, we perform a basic Sentiment Analysis of the answers to the consultation questions 1, 4, 5, and 8, using Python's Vader module.\n",
    "\n",
    "Pipeline:\n",
    "1. Sentence Tokenise answers\n",
    "2. Calculate sentiment polarity score for each sentence within each answer\n",
    "3. Compute aggregated sentiment score for each answer (mean/median of sentiment scores of all sentences making up )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Imports and Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up working directory\n",
    "\n",
    "cwd = os.chdir('/Users/alessia/Documents/DataScience/NLP_Project/Outputs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import user-created funcions for text mining and sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alessia/anaconda3/lib/python3.6/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "%run '/Users/alessia/Documents/DataScience/NLP_Project/Code/Improving_functions.ipynb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in data (note header is spread over two rows)\n",
    "\n",
    "cons1_df = pd.read_csv(\"cons1_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore data\n",
    "\n",
    "#[print(str(num) + ' = ' + question) for num, question in enumerate(cons1_df.columns)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Sentiment Analysis of questions 1, 4, 5 and 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get column index of questions we wan to calculate sentiment score for\n",
    "\n",
    "idx_Q1 = cons1_df.columns.get_loc(str([col for col in cons1_df if 'census methods' in str(col)][0]))\n",
    "idx_Q4 = cons1_df.columns.get_loc(str([col for col in cons1_df if '4. 1. ' in str(col)][0]))\n",
    "idx_Q5 = cons1_df.columns.get_loc(str([col for col in cons1_df if '5. 1.' in str(col)][0]))\n",
    "idx_Q8 = cons1_df.columns.get_loc(str([col for col in cons1_df if '8.' in str(col)][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 44, 46, 49)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checks\n",
    "idx_Q1, idx_Q4, idx_Q5, idx_Q8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a dictionary with indeces of answers to be analyses (values), \n",
    "# and name of new variables containing sentenced-tokenised versions (key)\n",
    "col_idx_dict = {\"Q1_ST\":idx_Q1, \"Q4_ST\":idx_Q4, \"Q5_ST\":idx_Q5, \"Q8_ST\":idx_Q8}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Sentence Tokenise answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new dataset columns containing sentence-tokenised answers\n",
    "for q, idx in col_idx_dict.items() :\n",
    "\n",
    "    result = sent_tokenise_answer(cons1_df.iloc[:, idx])\n",
    "    \n",
    "    cons1_df.loc[:, q] = result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the result\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "cons1_df.iloc[:5, [idx_Q1, -4, idx_Q4, -3, idx_Q5, -2, idx_Q8, -1]];  #OK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Calculate Sentiment score for each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a dictionary with indeces of answers to be analyses (values), \n",
    "# and name of new variables containing sentenced-tokenised versions (key)\n",
    "col_idx_dict = {\"Q1_ST\":idx_Q1, \"Q4_ST\":idx_Q4, \"Q5_ST\":idx_Q5, \"Q8_ST\":idx_Q8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Take a look at the result\n",
    "cons1_df.iloc[:, [idx_Q1, -4, idx_Q4, -3, idx_Q5, -2, idx_Q8, -1]];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1_Sentiment</th>\n",
       "      <th>Q4_Sentiment</th>\n",
       "      <th>Q5_Sentiment</th>\n",
       "      <th>Q8_Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>736.000000</td>\n",
       "      <td>523.000000</td>\n",
       "      <td>396.000000</td>\n",
       "      <td>490.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.388333</td>\n",
       "      <td>0.073410</td>\n",
       "      <td>0.338060</td>\n",
       "      <td>0.092375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.523643</td>\n",
       "      <td>0.515057</td>\n",
       "      <td>0.425649</td>\n",
       "      <td>0.575458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.981700</td>\n",
       "      <td>-0.983000</td>\n",
       "      <td>-0.904200</td>\n",
       "      <td>-0.969100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.318200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.361200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.493900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.440400</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.866425</td>\n",
       "      <td>0.440400</td>\n",
       "      <td>0.690275</td>\n",
       "      <td>0.633900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.999800</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.995400</td>\n",
       "      <td>0.998800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0      Q1_Sentiment  Q4_Sentiment  Q5_Sentiment  Q8_Sentiment\n",
       "count    736.000000    523.000000    396.000000    490.000000\n",
       "mean       0.388333      0.073410      0.338060      0.092375\n",
       "std        0.523643      0.515057      0.425649      0.575458\n",
       "min       -0.981700     -0.983000     -0.904200     -0.969100\n",
       "25%        0.000000     -0.318200      0.000000     -0.361200\n",
       "50%        0.493900      0.000000      0.440400      0.000000\n",
       "75%        0.866425      0.440400      0.690275      0.633900\n",
       "max        0.999800      0.999900      0.995400      0.998800"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary satistics\n",
    "cons1_df.iloc[:, [idx_Q1, -4, idx_Q4, -3, idx_Q5, -2, idx_Q8, -1]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save dataset\n",
    "\n",
    "cons1_df.to_csv('/Users/alessia/Documents/DataScience/NLP_Project/Outputs/cons1_SA_df.csv', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
