{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports and Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alessia/anaconda3/lib/python3.6/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "#### Imports and Set Up\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk import pos_tag\n",
    "\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    " \n",
    "porter_stemmer = PorterStemmer()\n",
    "wordnet_lemmatiser = WordNetLemmatizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cwd = os.chdir(\"/Users/alessia/Documents/DataScience/NLP_Project/Data\")\n",
    "cwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cons1_df = pd.read_csv(\"/Users/alessia/Documents/DataScience/NLP_Project/Outputs/cons1_cleantext_SA_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### POS tagging answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get columns' index\n",
    "idx_Q1 = cons1_df.columns.get_loc(str([col for col in cons1_df if 'census methods' in str(col)][0]))\n",
    "idx_Q4 = cons1_df.columns.get_loc(str([col for col in cons1_df if '4. 1. ' in str(col)][0]))\n",
    "idx_Q5 = cons1_df.columns.get_loc(str([col for col in cons1_df if '5. 1.' in str(col)][0]))\n",
    "idx_Q8 = cons1_df.columns.get_loc(str([col for col in cons1_df if '8.' in str(col)][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Q1': 41, 'Q4': 45, 'Q5': 47, 'Q8': 50}\n",
      "dict_items([('Q1', 41), ('Q4', 45), ('Q5', 47), ('Q8', 50)])\n",
      "dict_values([41, 45, 47, 50])\n"
     ]
    }
   ],
   "source": [
    "# Save them in a dictionary\n",
    "col_idx_dict = {\"Q1\":idx_Q1, \"Q4\":idx_Q4, \"Q5\":idx_Q5, \"Q8\":idx_Q8}\n",
    "\n",
    "print(col_idx_dict)\n",
    "print(col_idx_dict.items())\n",
    "print(col_idx_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define function to tag Part-of-Speech of text answers\n",
    "\n",
    "def tokenise_POS_text(data, col_ind, stop_words, no_stopwords = True, no_punctuation = True) :\n",
    "    \"\"\"Return a list with POS tags of specified data columns containing text after\n",
    "    removing punctuation (default) and non-alphabetic tokens\"\"\"\n",
    "    \n",
    "    import pandas as pd\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    \n",
    "    from nltk import pos_tag\n",
    "    \n",
    "    # empty list collector\n",
    "    tokens_bag = []\n",
    "    \n",
    "    for answer in data.iloc[:, col_ind] :   \n",
    "        \n",
    "        # no answer was provided, return NA\n",
    "        if pd.isnull(answer) : \n",
    "            tokens_bag.append(np.nan)\n",
    "            \n",
    "        # an answer was provided    \n",
    "        else : \n",
    "                \n",
    "            # word-tokenise the answer\n",
    "            words = word_tokenize(answer)\n",
    "        \n",
    "            # convert to lower case\n",
    "            words = [w.lower() for w in words]\n",
    "            \n",
    "            \n",
    "            if no_punctuation : # no_punctuation = True\n",
    "                \n",
    "                # remove punctuation \n",
    "                import string\n",
    "                table = str.maketrans('', '', string.punctuation)\n",
    "                words = [w.translate(table) for w in words]\n",
    "                \n",
    "                # remove remaining tokens that are not alphabetic\n",
    "                only_words = [w for w in words if w.isalpha()]\n",
    "                \n",
    "            #else :\n",
    "            #    continue\n",
    "                \n",
    "            \n",
    "            ### THIS DOES NOT WORK... ###\n",
    "            if no_stopwords :    # no_stopwirds = True\n",
    "                \n",
    "                # filter out stop words from each answer\n",
    "                only_words = [w for w in only_words if not w in stop_words]\n",
    "                \n",
    "            #else :   \n",
    "            #    continue\n",
    "            \n",
    "            \n",
    "            # calculate Part-Of-Speech\n",
    "            pos_answer = pos_tag(only_words)\n",
    "\n",
    "            tokens_bag.append(pos_answer)\n",
    "    \n",
    "    return(tokens_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#batch_pos_tag(cons1_df['Q1'])   # ERROR name 'batch_pos_tag' is not defined "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tokenise_POS_text(cons1_df.iloc[:, ], col_ind=idx_Q8);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.update('would', 'could', 'might', 'may')\n",
    "\n",
    "# do we want to keep in \"no\"? \"yes\" is not a stopword..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(stopwords.words('english')))\n",
    "stop_words;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create new dataset columns containing the POS-tagged texts\n",
    "\n",
    "for q, idx in col_idx_dict.items() :\n",
    "\n",
    "    result = tokenise_POS_text(cons1_df, idx, stop_words=stop_words)\n",
    "    new_q = q + '_pos'\n",
    "    \n",
    "    #print(type(result))\n",
    "    #print(type(cons1_df.iloc[:, idx]))\n",
    "    #print(type(new_q))\n",
    "    \n",
    "    se_result = pd.Series(result)      # had to turn this into a Pandas series first, otherwise ERROR\n",
    "    #print(se_result[1:5])\n",
    "    #print(cons1_df.iloc[:, idx].head())\n",
    "    \n",
    "    cons1_df.loc[:, new_q] = se_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Respondent ID</th>\n",
       "      <th>Collector ID</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>End Date</th>\n",
       "      <th>IP Address</th>\n",
       "      <th>Email Address</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>...</th>\n",
       "      <th>Q5_clean</th>\n",
       "      <th>Q8_clean</th>\n",
       "      <th>Q1_cl_sentiment</th>\n",
       "      <th>Q4_cl_sentiment</th>\n",
       "      <th>Q5_cl_sentiment</th>\n",
       "      <th>Q8_cl_sentiment</th>\n",
       "      <th>Q1_pos</th>\n",
       "      <th>Q4_pos</th>\n",
       "      <th>Q5_pos</th>\n",
       "      <th>Q8_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3001215611</td>\n",
       "      <td>45151668</td>\n",
       "      <td>2014-01-05 02:42:21</td>\n",
       "      <td>2014-01-05 02:44:13</td>\n",
       "      <td>49.224.154.245</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3001062135</td>\n",
       "      <td>45151668</td>\n",
       "      <td>2014-01-04 21:34:56</td>\n",
       "      <td>2014-01-04 21:35:12</td>\n",
       "      <td>79.69.231.100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2990699680</td>\n",
       "      <td>45151668</td>\n",
       "      <td>2013-12-23 16:54:29</td>\n",
       "      <td>2013-12-23 17:00:18</td>\n",
       "      <td>109.148.186.17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2990403881</td>\n",
       "      <td>45151668</td>\n",
       "      <td>2013-12-23 12:17:33</td>\n",
       "      <td>2013-12-23 12:29:22</td>\n",
       "      <td>217.36.37.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>date statistics postcode sector equivalent lev...</td>\n",
       "      <td>essential changes census methodology thoroughl...</td>\n",
       "      <td>0.5719</td>\n",
       "      <td>0.6486</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>0.8910</td>\n",
       "      <td>[(moving, VBG), (primarily, RB), (online, JJ),...</td>\n",
       "      <td>[(important, JJ), (census, NN), (provide, VBP)...</td>\n",
       "      <td>[(date, NN), (statistics, NNS), (postcode, VBP...</td>\n",
       "      <td>[(essential, JJ), (changes, NNS), (census, VBP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2985513376</td>\n",
       "      <td>45151668</td>\n",
       "      <td>2013-12-19 11:35:42</td>\n",
       "      <td>2013-12-19 11:43:35</td>\n",
       "      <td>86.12.129.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>would allow council respond effectively changi...</td>\n",
       "      <td>measures must put place ensure one excluded on...</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.8360</td>\n",
       "      <td>0.9590</td>\n",
       "      <td>0.4939</td>\n",
       "      <td>[(regular, JJ), (full, JJ), (population, NN), ...</td>\n",
       "      <td>[(would, MD), (lose, VB), (ability, NN), (unde...</td>\n",
       "      <td>[(would, MD), (allow, VB), (council, NN), (res...</td>\n",
       "      <td>[(measures, NNS), (must, MD), (put, VB), (plac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2983385436</td>\n",
       "      <td>45151668</td>\n",
       "      <td>2013-12-18 11:07:44</td>\n",
       "      <td>2013-12-18 16:42:33</td>\n",
       "      <td>46.33.158.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>users census place premium current model howev...</td>\n",
       "      <td>0.9648</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9657</td>\n",
       "      <td>[(privacy, NN), (clear, JJ), (concern, NN), (w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(users, NNS), (census, VBP), (place, NN), (pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  Respondent ID  Collector ID           Start Date  \\\n",
       "0           0             0     3001215611      45151668  2014-01-05 02:42:21   \n",
       "1           1             1     3001062135      45151668  2014-01-04 21:34:56   \n",
       "2           2             2     2990699680      45151668  2013-12-23 16:54:29   \n",
       "3           3             3     2990403881      45151668  2013-12-23 12:17:33   \n",
       "4           4             4     2985513376      45151668  2013-12-19 11:35:42   \n",
       "5           5             5     2983385436      45151668  2013-12-18 11:07:44   \n",
       "\n",
       "              End Date      IP Address  Email Address  First Name  Last Name  \\\n",
       "0  2014-01-05 02:44:13  49.224.154.245            NaN         NaN        NaN   \n",
       "1  2014-01-04 21:35:12   79.69.231.100            NaN         NaN        NaN   \n",
       "2  2013-12-23 17:00:18  109.148.186.17            NaN         NaN        NaN   \n",
       "3  2013-12-23 12:29:22    217.36.37.20            NaN         NaN        NaN   \n",
       "4  2013-12-19 11:43:35     86.12.129.3            NaN         NaN        NaN   \n",
       "5  2013-12-18 16:42:33    46.33.158.20            NaN         NaN        NaN   \n",
       "\n",
       "                         ...                          \\\n",
       "0                        ...                           \n",
       "1                        ...                           \n",
       "2                        ...                           \n",
       "3                        ...                           \n",
       "4                        ...                           \n",
       "5                        ...                           \n",
       "\n",
       "                                            Q5_clean  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3  date statistics postcode sector equivalent lev...   \n",
       "4  would allow council respond effectively changi...   \n",
       "5                                                NaN   \n",
       "\n",
       "                                            Q8_clean Q1_cl_sentiment  \\\n",
       "0                                                NaN             NaN   \n",
       "1                                                NaN             NaN   \n",
       "2                                                NaN             NaN   \n",
       "3  essential changes census methodology thoroughl...          0.5719   \n",
       "4  measures must put place ensure one excluded on...          0.9848   \n",
       "5  users census place premium current model howev...          0.9648   \n",
       "\n",
       "  Q4_cl_sentiment Q5_cl_sentiment Q8_cl_sentiment  \\\n",
       "0             NaN             NaN             NaN   \n",
       "1             NaN             NaN             NaN   \n",
       "2             NaN             NaN             NaN   \n",
       "3          0.6486          0.4404          0.8910   \n",
       "4          0.8360          0.9590          0.4939   \n",
       "5             NaN             NaN          0.9657   \n",
       "\n",
       "                                              Q1_pos  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3  [(moving, VBG), (primarily, RB), (online, JJ),...   \n",
       "4  [(regular, JJ), (full, JJ), (population, NN), ...   \n",
       "5  [(privacy, NN), (clear, JJ), (concern, NN), (w...   \n",
       "\n",
       "                                              Q4_pos  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3  [(important, JJ), (census, NN), (provide, VBP)...   \n",
       "4  [(would, MD), (lose, VB), (ability, NN), (unde...   \n",
       "5                                                NaN   \n",
       "\n",
       "                                              Q5_pos  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3  [(date, NN), (statistics, NNS), (postcode, VBP...   \n",
       "4  [(would, MD), (allow, VB), (council, NN), (res...   \n",
       "5                                                NaN   \n",
       "\n",
       "                                              Q8_pos  \n",
       "0                                                NaN  \n",
       "1                                                NaN  \n",
       "2                                                NaN  \n",
       "3  [(essential, JJ), (changes, NNS), (census, VBP...  \n",
       "4  [(measures, NNS), (must, MD), (put, VB), (plac...  \n",
       "5  [(users, NNS), (census, VBP), (place, NN), (pr...  \n",
       "\n",
       "[6 rows x 68 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checks\n",
    "cons1_df.columns.values\n",
    "cons1_df.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatisation of answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get columns' index of POS-tagged answers\n",
    "idx_Q1p = cons1_df.columns.get_loc('Q1_pos')\n",
    "idx_Q4p = cons1_df.columns.get_loc('Q4_pos')\n",
    "idx_Q5p = cons1_df.columns.get_loc('Q5_pos')\n",
    "idx_Q8p = cons1_df.columns.get_loc('Q8_pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save them in a dictionary\n",
    "colpos_idx_dict = {\"Q1_pos\":idx_Q1p, \"Q4_pos\":idx_Q4p, \"Q5_pos\":idx_Q5p, \"Q8_pos\":idx_Q8p}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace float nan's with empty srings\n",
    "\n",
    "# Create new dataset columns containing the POS-tagged texts\n",
    "\n",
    "for q, idx in colpos_idx_dict.items() :\n",
    "    \n",
    "    cons1_df.iloc[:, idx] = cons1_df.iloc[:, idx].replace(np.nan, '', regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "   Unnamed: 0  Unnamed: 0.1  Respondent ID  Collector ID           Start Date  \\\n",
      "0           0             0     3001215611      45151668  2014-01-05 02:42:21   \n",
      "1           1             1     3001062135      45151668  2014-01-04 21:34:56   \n",
      "2           2             2     2990699680      45151668  2013-12-23 16:54:29   \n",
      "3           3             3     2990403881      45151668  2013-12-23 12:17:33   \n",
      "\n",
      "              End Date      IP Address  Email Address  First Name  Last Name  \\\n",
      "0  2014-01-05 02:44:13  49.224.154.245            NaN         NaN        NaN   \n",
      "1  2014-01-04 21:35:12   79.69.231.100            NaN         NaN        NaN   \n",
      "2  2013-12-23 17:00:18  109.148.186.17            NaN         NaN        NaN   \n",
      "3  2013-12-23 12:29:22    217.36.37.20            NaN         NaN        NaN   \n",
      "\n",
      "                         ...                          \\\n",
      "0                        ...                           \n",
      "1                        ...                           \n",
      "2                        ...                           \n",
      "3                        ...                           \n",
      "\n",
      "                                            Q5_clean  \\\n",
      "0                                                NaN   \n",
      "1                                                NaN   \n",
      "2                                                NaN   \n",
      "3  date statistics postcode sector equivalent lev...   \n",
      "\n",
      "                                            Q8_clean Q1_cl_sentiment  \\\n",
      "0                                                NaN             NaN   \n",
      "1                                                NaN             NaN   \n",
      "2                                                NaN             NaN   \n",
      "3  essential changes census methodology thoroughl...          0.5719   \n",
      "\n",
      "  Q4_cl_sentiment Q5_cl_sentiment Q8_cl_sentiment  \\\n",
      "0             NaN             NaN             NaN   \n",
      "1             NaN             NaN             NaN   \n",
      "2             NaN             NaN             NaN   \n",
      "3          0.6486          0.4404           0.891   \n",
      "\n",
      "                                              Q1_pos  \\\n",
      "0                                                      \n",
      "1                                                      \n",
      "2                                                      \n",
      "3  [(moving, VBG), (primarily, RB), (online, JJ),...   \n",
      "\n",
      "                                              Q4_pos  \\\n",
      "0                                                      \n",
      "1                                                      \n",
      "2                                                      \n",
      "3  [(important, JJ), (census, NN), (provide, VBP)...   \n",
      "\n",
      "                                              Q5_pos  \\\n",
      "0                                                      \n",
      "1                                                      \n",
      "2                                                      \n",
      "3  [(date, NN), (statistics, NNS), (postcode, VBP...   \n",
      "\n",
      "                                              Q8_pos  \n",
      "0                                                     \n",
      "1                                                     \n",
      "2                                                     \n",
      "3  [(essential, JJ), (changes, NNS), (census, VBP...  \n",
      "\n",
      "[4 rows x 68 columns]\n"
     ]
    }
   ],
   "source": [
    "print(type(cons1_df.iloc[:, idx].head(4)))\n",
    "print(cons1_df.iloc[:,].head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TBC : should impement something like this...\n",
    "# https://stackoverflow.com/questions/15586721/wordnet-lemmatization-and-pos-tagging-in-python\n",
    "\n",
    "# The following function would map the treebank tags to WordNet part of speech names:\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    elif treebank_tag.startswith('S'):\n",
    "        return wordnet.ADJ_SAT\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_wordnet_pos('MD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new dataset columns containing the POS-tagged texts\n",
    "\n",
    "for q, idx in colpos_idx_dict.items() :\n",
    "\n",
    "    # set new variable name\n",
    "    new_q = q + '_lemma'\n",
    "    \n",
    "    \n",
    "    # extract columns with answers\n",
    "    answer_col = cons1_df.iloc[:, idx]\n",
    "    \n",
    "    answer_col = answer_col.tolist()\n",
    "    #print(type(answer_col))\n",
    "    #print(answer_col[1:4])\n",
    "    \n",
    "    \n",
    "    # collector for all answers within that answer_col\n",
    "    lemma_big_bag = []\n",
    "    \n",
    "    \n",
    "    for answer in answer_col :\n",
    "        \n",
    "        lemma_bag = []\n",
    "        \n",
    "        #print(answer)\n",
    "        #print(len(answer))\n",
    "        \n",
    "        # an answer was provided\n",
    "        if len(answer) > 0 :\n",
    "            \n",
    "            for POStext_pair in answer :\n",
    "                \n",
    "                #print(POStext_pair[0])\n",
    "                #print(POStext_pair[1])\n",
    "                \n",
    "                #print(type(POStext_pair[0]))\n",
    "                #print(type(POStext_pair[1]))\n",
    "                \n",
    "                #print('wordnet pos = ' + get_wordnet_pos(POStext_pair[1]))\n",
    "                #print('type wordnet pos = ' + str(type(get_wordnet_pos(POStext_pair[1]))))\n",
    "                \n",
    "                #print( get_wordnet_pos(POStext_pair[1]) == '')\n",
    "                \n",
    "                \n",
    "                # the treebank POS does not have a wordnet POS equivalent\n",
    "                if get_wordnet_pos(POStext_pair[1]) == '' :\n",
    "                    \n",
    "                    lemma = POStext_pair[0]\n",
    "                    #print('lemma = ' + lemma)\n",
    "                    #print(type(lemma))\n",
    "                    \n",
    "                \n",
    "                \n",
    "                # the treebank POS does have a wordnet POS equivalent\n",
    "                else :\n",
    "                    \n",
    "                    lemma = wordnet_lemmatiser.lemmatize(POStext_pair[0], pos=get_wordnet_pos(POStext_pair[1]))\n",
    "                \n",
    "                    #print('lemma = ' + lemma)\n",
    "                    #print(type(lemma))\n",
    "                    \n",
    "                \n",
    "                lemma_bag.append(lemma)\n",
    "                #print(lemma_bag)\n",
    "                #print(type(lemma_bag))\n",
    "                \n",
    "        else :\n",
    "            \n",
    "            lemma_bag.append(str(\"\"))\n",
    "        \n",
    "        \n",
    "        lemma_big_bag.append(lemma_bag)\n",
    "        \n",
    "    \n",
    "    \n",
    "    se_lemma_result = pd.Series(lemma_big_bag)      # had to turn this into a Pandas series first, otherwise ERROR\n",
    "    \n",
    "    cons1_df.loc[:, new_q] = se_lemma_result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  Unnamed: 0.1  Respondent ID  Collector ID           Start Date  \\\n",
      "0           0             0     3001215611      45151668  2014-01-05 02:42:21   \n",
      "1           1             1     3001062135      45151668  2014-01-04 21:34:56   \n",
      "2           2             2     2990699680      45151668  2013-12-23 16:54:29   \n",
      "3           3             3     2990403881      45151668  2013-12-23 12:17:33   \n",
      "\n",
      "              End Date      IP Address  Email Address  First Name  Last Name  \\\n",
      "0  2014-01-05 02:44:13  49.224.154.245            NaN         NaN        NaN   \n",
      "1  2014-01-04 21:35:12   79.69.231.100            NaN         NaN        NaN   \n",
      "2  2013-12-23 17:00:18  109.148.186.17            NaN         NaN        NaN   \n",
      "3  2013-12-23 12:29:22    217.36.37.20            NaN         NaN        NaN   \n",
      "\n",
      "                         ...                          Q5_cl_sentiment  \\\n",
      "0                        ...                                      NaN   \n",
      "1                        ...                                      NaN   \n",
      "2                        ...                                      NaN   \n",
      "3                        ...                                   0.4404   \n",
      "\n",
      "  Q8_cl_sentiment                                             Q1_pos  \\\n",
      "0             NaN                                                      \n",
      "1             NaN                                                      \n",
      "2             NaN                                                      \n",
      "3           0.891  [(moving, VBG), (primarily, RB), (online, JJ),...   \n",
      "\n",
      "                                              Q4_pos  \\\n",
      "0                                                      \n",
      "1                                                      \n",
      "2                                                      \n",
      "3  [(important, JJ), (census, NN), (provide, VBP)...   \n",
      "\n",
      "                                              Q5_pos  \\\n",
      "0                                                      \n",
      "1                                                      \n",
      "2                                                      \n",
      "3  [(date, NN), (statistics, NNS), (postcode, VBP...   \n",
      "\n",
      "                                              Q8_pos  \\\n",
      "0                                                      \n",
      "1                                                      \n",
      "2                                                      \n",
      "3  [(essential, JJ), (changes, NNS), (census, VBP...   \n",
      "\n",
      "                                        Q1_pos_lemma  \\\n",
      "0                                                 []   \n",
      "1                                                 []   \n",
      "2                                                 []   \n",
      "3  [move, primarily, online, census, inevitable, ...   \n",
      "\n",
      "                                        Q4_pos_lemma  \\\n",
      "0                                                 []   \n",
      "1                                                 []   \n",
      "2                                                 []   \n",
      "3  [important, census, provide, data, postcode, s...   \n",
      "\n",
      "                                        Q5_pos_lemma  \\\n",
      "0                                                 []   \n",
      "1                                                 []   \n",
      "2                                                 []   \n",
      "3  [date, statistic, postcode, sector, equivalent...   \n",
      "\n",
      "                                        Q8_pos_lemma  \n",
      "0                                                 []  \n",
      "1                                                 []  \n",
      "2                                                 []  \n",
      "3  [essential, change, census, methodology, thoro...  \n",
      "\n",
      "[4 rows x 72 columns]\n"
     ]
    }
   ],
   "source": [
    "cons1_df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
