{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### INTRO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports and Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cwd = os.chdir(\"/Users/alessia/Documents/DataScience/NLP_Project/Data\")\n",
    "cwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cons1_df = pd.read_csv(\"/Users/alessia/Documents/DataScience/NLP_Project/Outputs/cons1_lemmas_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cons1_df.columns.values;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentiment Analysis on mellatised answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select columns that contains the answers to be tokenised for punctuation-/non-alphabetic token-/stopword-removal and sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get columns' index and save it in a dictionary with name of new variable as key (Qx_lemma_SA)\n",
    "col_idx_dict = {}\n",
    "\n",
    "for col in ['Q1_pos_lemma', 'Q4_pos_lemma','Q5_pos_lemma', 'Q8_pos_lemma'] :\n",
    "    col_idx_dict[col.split('_')[0] + '_lemma_SA' ] = cons1_df.columns.get_loc(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Q1_lemma_SA': 69, 'Q4_lemma_SA': 70, 'Q5_lemma_SA': 71, 'Q8_lemma_SA': 72}\n"
     ]
    }
   ],
   "source": [
    "# Checks\n",
    "print(col_idx_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define function to calculate polarity score for the answers in our dataset\n",
    "\n",
    "# import key modules\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "    \n",
    "\n",
    "def get_sentiment_score(data, col_ind) :\n",
    "    \"\"\" Return list of polarity scores for values in the specified column \"\"\"\n",
    "    \n",
    "    # empty list collector of scores\n",
    "    sentiment_bag = []\n",
    "    \n",
    "    for answer in data.iloc[:, col_ind] :\n",
    "        \n",
    "        # no answer was provided, return NA\n",
    "        if pd.isnull(answer) : \n",
    "            sentiment_bag.append(np.nan)\n",
    "            \n",
    "        else :\n",
    "            sentiment_bag.append(analyser.polarity_scores(answer)['compound'])\n",
    "    \n",
    "    return(sentiment_bag)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['']\n",
      "<class 'str'>\n",
      "['']\n",
      "<class 'str'>\n",
      "['']\n",
      "<class 'str'>\n",
      "['']\n",
      "<class 'str'>\n",
      "['']\n",
      "<class 'str'>\n",
      "['']\n",
      "<class 'str'>\n",
      "['move', 'primarily', 'online', 'census', 'inevitable', 'necessary', 'evolution', 'exist', 'approach', 'admin', 'data', 'survey', 'unknown', 'quantity', 'dependent', 'quality', 'admin', 'data', 'not', 'clear', 'well', 'would', 'fulfil', 'primary', 'aim', 'census', 'produce', 'accurate', 'independent', 'estimate', 'size', 'composition', 'population']\n",
      "<class 'str'>\n",
      "['move', 'primarily', 'online', 'census', 'inevitable', 'necessary', 'evolution', 'exist', 'approach', 'admin', 'data', 'survey', 'unknown', 'quantity', 'dependent', 'quality', 'admin', 'data', 'not', 'clear', 'well', 'would', 'fulfil', 'primary', 'aim', 'census', 'produce', 'accurate', 'independent', 'estimate', 'size', 'composition', 'population']\n",
      "<class 'str'>\n",
      "[]\n",
      "['']\n",
      "<class 'str'>\n",
      "['']\n",
      "<class 'str'>\n",
      "['']\n",
      "<class 'str'>\n",
      "['']\n",
      "<class 'str'>\n",
      "['']\n",
      "<class 'str'>\n",
      "['']\n",
      "<class 'str'>\n",
      "['important', 'census', 'provide', 'data', 'postcode', 'sector', 'equivalent', 'level', 'minimum', 'provide', 'medium', 'research', 'industry', 'flexibility', 'create', 'bespoke', 'relevant', 'area', 'basis', 'reporting']\n",
      "<class 'str'>\n",
      "['important', 'census', 'provide', 'data', 'postcode', 'sector', 'equivalent', 'level', 'minimum', 'provide', 'medium', 'research', 'industry', 'flexibility', 'create', 'bespoke', 'relevant', 'area', 'basis', 'reporting']\n",
      "<class 'str'>\n",
      "[]\n",
      "['']\n",
      "<class 'str'>\n",
      "['']\n",
      "<class 'str'>\n",
      "['']\n",
      "<class 'str'>\n",
      "['']\n",
      "<class 'str'>\n",
      "['']\n",
      "<class 'str'>\n",
      "['']\n",
      "<class 'str'>\n",
      "['up', 'date', 'statistic', 'postcode', 'sector', 'equivalent', 'level', 'would', 'beneficial', 'provided', 'accurate', 'credible']\n",
      "<class 'str'>\n",
      "['up', 'date', 'statistic', 'postcode', 'sector', 'equivalent', 'level', 'would', 'beneficial', 'provided', 'accurate', 'credible']\n",
      "<class 'str'>\n",
      "[]\n",
      "['']\n",
      "<class 'str'>\n",
      "['']\n",
      "<class 'str'>\n",
      "['']\n",
      "<class 'str'>\n",
      "['']\n",
      "<class 'str'>\n",
      "['']\n",
      "<class 'str'>\n",
      "['']\n",
      "<class 'str'>\n",
      "['essential', 'change', 'census', 'methodology', 'thoroughly', 'test', 'pilot', 'advance', 'implementation', 'risk', 'well', 'summarise', 'consultation', 'document', 'primarily', 'online', 'census', 'safer', 'option', 'immediate', 'future', 'not', 'without', 'risk', 'administrative', 'data', 'primarily', 'create', 'maintain', 'another', 'purpose', 'may', 'not', 'provide', 'accurate', 'basis', 'produce', 'overall', 'population', 'estimate', 'not', 'clear', 'adequate', 'sample', 'frame', 'could', 'construct', 'propose', 'annual', 'survey', 'may', 'still', 'require', 'considerable', 'field', 'force', 'enumerator', 'ground', 'use', 'administrative', 'data', 'may', 'prove', 'effective', 'solution', 'need', 'particular', 'government', 'department', 'may', 'not', 'provide', 'usable', 'data', 'market', 'research', 'industry']\n",
      "<class 'str'>\n",
      "['essential', 'change', 'census', 'methodology', 'thoroughly', 'test', 'pilot', 'advance', 'implementation', 'risk', 'well', 'summarise', 'consultation', 'document', 'primarily', 'online', 'census', 'safer', 'option', 'immediate', 'future', 'not', 'without', 'risk', 'administrative', 'data', 'primarily', 'create', 'maintain', 'another', 'purpose', 'may', 'not', 'provide', 'accurate', 'basis', 'produce', 'overall', 'population', 'estimate', 'not', 'clear', 'adequate', 'sample', 'frame', 'could', 'construct', 'propose', 'annual', 'survey', 'may', 'still', 'require', 'considerable', 'field', 'force', 'enumerator', 'ground', 'use', 'administrative', 'data', 'may', 'prove', 'effective', 'solution', 'need', 'particular', 'government', 'department', 'may', 'not', 'provide', 'usable', 'data', 'market', 'research', 'industry']\n",
      "<class 'str'>\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# untokenise the sentence: return one unique string for each answer in prep for sentiment analysis\n",
    "import string\n",
    "\n",
    "for q, idx in col_idx_dict.items():\n",
    "    \n",
    "    sentiment_bag = []\n",
    "\n",
    "    for answer in cons1_df.iloc[:, idx] :\n",
    "        \n",
    "        print(answer)\n",
    "        print(type(answer))\n",
    "        \n",
    "        answer0 = word_tokenize(answer)\n",
    "        answer1 = \"\".join([\"\"+i if not i.startswith(\"'\") and i not in string.punctuation else i for i in answer]).strip()\n",
    "        print(answer1)\n",
    "        print(type(answer1))\n",
    "        \n",
    "        #answer2 = detokenizer.detokenize(answer1, return_str=True)\n",
    "            \n",
    "        #print(answer2)\n",
    "        \n",
    "        # no answer was provided, return NA\n",
    "        #if pd.isnull(answer2) : \n",
    "        #    sentiment_bag.append(np.nan)\n",
    "            \n",
    "        #else :\n",
    "        #    sentiment_bag.append(analyser.polarity_scores(answer2)['compound'])\n",
    "    \n",
    "    print(sentiment_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create new dataset columns with sentiment polarity scores of lemmatised texts\n",
    "\n",
    "from nltk.tokenize.moses import MosesDetokenizer\n",
    "detokenizer = MosesDetokenizer()\n",
    "        \n",
    "for q, idx in col_idx_dict.items():\n",
    "    \n",
    "    result = get_sentiment_score(cons1_df, idx)\n",
    "    cons1_df.loc[:, q] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1_Sentiment</th>\n",
       "      <th>Q1_cl_sentiment</th>\n",
       "      <th>Q1_lemma_SA</th>\n",
       "      <th>Q4_Sentiment</th>\n",
       "      <th>Q4_cl_sentiment</th>\n",
       "      <th>Q4_lemma_SA</th>\n",
       "      <th>Q5_Sentiment</th>\n",
       "      <th>Q5_cl_sentiment</th>\n",
       "      <th>Q5_lemma_SA</th>\n",
       "      <th>Q8_Sentiment</th>\n",
       "      <th>Q8_cl_sentiment</th>\n",
       "      <th>Q8_lemma_SA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.4585</td>\n",
       "      <td>0.5719</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6486</td>\n",
       "      <td>0.6486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7596</td>\n",
       "      <td>0.8910</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9814</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8360</td>\n",
       "      <td>0.8360</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9651</td>\n",
       "      <td>0.9590</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.4939</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.9648</td>\n",
       "      <td>0.9648</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9619</td>\n",
       "      <td>0.9657</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.1887</td>\n",
       "      <td>-0.7193</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.5574</td>\n",
       "      <td>-0.5574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4939</td>\n",
       "      <td>0.7693</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q1_Sentiment  Q1_cl_sentiment  Q1_lemma_SA  Q4_Sentiment  Q4_cl_sentiment  \\\n",
       "3       -0.4585           0.5719          0.0        0.6486           0.6486   \n",
       "4        0.9814           0.9848          0.0        0.8360           0.8360   \n",
       "5        0.9648           0.9648          0.0           NaN              NaN   \n",
       "6           NaN              NaN          0.0           NaN              NaN   \n",
       "7        0.1887          -0.7193          0.0           NaN              NaN   \n",
       "\n",
       "   Q4_lemma_SA  Q5_Sentiment  Q5_cl_sentiment  Q5_lemma_SA  Q8_Sentiment  \\\n",
       "3          0.0        0.4404           0.4404          0.0        0.7596   \n",
       "4          0.0        0.9651           0.9590          0.0        0.2500   \n",
       "5          0.0           NaN              NaN          0.0        0.9619   \n",
       "6          0.0           NaN              NaN          0.0           NaN   \n",
       "7          0.0       -0.5574          -0.5574          0.0        0.4939   \n",
       "\n",
       "   Q8_cl_sentiment  Q8_lemma_SA  \n",
       "3           0.8910          0.0  \n",
       "4           0.4939          0.0  \n",
       "5           0.9657          0.0  \n",
       "6              NaN          0.0  \n",
       "7           0.7693          0.0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the result\n",
    "cons1_df.loc[3:7:, [\"Q1_Sentiment\", \"Q1_cl_sentiment\", 'Q1_lemma_SA',\n",
    "                    \"Q4_Sentiment\", \"Q4_cl_sentiment\", 'Q4_lemma_SA',\n",
    "                    \"Q5_Sentiment\", \"Q5_cl_sentiment\", 'Q5_lemma_SA',\n",
    "                    \"Q8_Sentiment\", \"Q8_cl_sentiment\", 'Q8_lemma_SA',]]\n",
    "\n",
    "# some changed drammatically!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Summary satistics\n",
    "cons1_df.loc[:, [\"Q1_Sentiment\", \"Q1_cl_sentiment\",\"Q4_Sentiment\", \"Q4_cl_sentiment\",\n",
    "                          \"Q5_Sentiment\", \"Q5_cl_sentiment\",\"Q8_Sentiment\", \"Q8_cl_sentiment\"]].describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
