{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to sentence-tokenise answers \n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import pandas as pd\n",
    "\n",
    "def sent_tokenise_answer(data, col_ind) :\n",
    "    \n",
    "    \"\"\" Function to sentence-tokenise answers. Return a list of lists that contain sentences as strings.\n",
    "        \n",
    "        data = name of the dataframe\n",
    "        col_ind = index of the column that contains the texts to be sentence-tokenised\n",
    "    \"\"\"\n",
    "    \n",
    "    sents_collector = []\n",
    "    \n",
    "    for answer in data.iloc[:, col_ind] :\n",
    "        \n",
    "        #if no answer was provided, return empty string list\n",
    "        if pd.isnull(answer) :\n",
    "            sents_collector.append(list(\"\"))\n",
    "            \n",
    "        # an answer was provided    \n",
    "        else :\n",
    "            sents_collector.append(sent_tokenize(answer))\n",
    "            \n",
    "    return(sents_collector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cons1_df = pd.read_csv(\"/Users/alessia/Documents/DataScience/NLP_Project/Outputs/cons1_lemmas_df.csv\", nrows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get column index of questions\n",
    "idx_Q1 = cons1_df.columns.get_loc(str([col for col in cons1_df if 'census methods' in str(col)][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_Q1     #42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to word-tokenise sentences \n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def word_tokenise_answer(data, col_ind) :\n",
    "    \n",
    "    \"\"\" Function to word-tokenise answers' sentences. Return a list of lists of words as strings. \n",
    "        Required input, a list of lists containing sentences as strings.\n",
    "        \n",
    "        data = name of the dataframe\n",
    "        col_ind = index of the column that contains the list of sentences to be word-tokenised\n",
    "    \"\"\"\n",
    "    \n",
    "    sents_collector = []\n",
    "    \n",
    "    for answer in data.iloc[:, col_ind] :\n",
    "        \n",
    "        #check\n",
    "        #if not answer :\n",
    "        #    print(\"answer is Null\")\n",
    "        \n",
    "        #if no answer was provided, return empty string list\n",
    "        if not answer:\n",
    "            sents_collector.append(list(\"\"))\n",
    "            \n",
    "        # an answer was provided    \n",
    "        else :\n",
    "            \n",
    "            words_collector = []\n",
    "            \n",
    "            for sent in answer :\n",
    "                words_collector.append(word_tokenize(sent))\n",
    "                \n",
    "            sents_collector.append(words_collector)\n",
    "            \n",
    "    return(sents_collector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[str, str, str, str, str, str, str, str, str, str, str, str, str, str]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[type(s) for s in sent_tokenise_answer(cons1_df, idx_Q1)[4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cons1_df.loc[:, 'test1'] = sent_tokenise_answer(cons1_df, idx_Q1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test1_idx = cons1_df.columns.get_loc('test1')      #73"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                   []\n",
       "1                                                   []\n",
       "2                                                   []\n",
       "3    [Moving to a primarily online census: an inevi...\n",
       "4    [A regular full population census is absolutel...\n",
       "Name: test1, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cons1_df.loc[:, 'test1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                   []\n",
       "1                                                   []\n",
       "2                                                   []\n",
       "3    [Moving to a primarily online census: an inevi...\n",
       "4    [A regular full population census is absolutel...\n",
       "Name: test1, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cons1_df.iloc[:, test1_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                                   []\n",
      "1                                                   []\n",
      "2                                                   []\n",
      "3    [Moving to a primarily online census: an inevi...\n",
      "4    [A regular full population census is absolutel...\n",
      "Name: test1, dtype: object\n",
      "[<class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>]\n",
      "[[], [], [], [['Moving', 'to', 'a', 'primarily', 'online', 'census', ':', 'an', 'inevitable', 'and', 'necessary', 'evolution', 'of', 'the', 'existing', 'approach', '.'], ['Admin', 'data', 'and', 'surveys', ':', 'an', 'unknown', 'quantity', ',', 'dependent', 'on', 'the', 'quality', 'of', 'admin', 'data', ',', 'and', 'not', 'clear', 'how', 'well', 'it', 'would', 'fulfil', 'the', 'primary', 'aim', 'of', 'a', 'census', ':', 'to', 'produce', 'an', 'accurate', 'and', 'independent', 'estimate', 'of', 'the', 'size', 'and', 'composition', 'of', 'the', 'population', '.']], [['A', 'regular', 'full', 'population', 'census', 'is', 'absolutely', 'necessary', '.'], ['It', 'is', 'the', 'only', 'way', 'to', 'ensure', 'that', 'all', 'population', 'and', 'social', 'statistical', 'estimates', 'and', 'projections', 'are', 'grounded', 'in', 'reality', '.'], ['Data', 'for', 'small', 'areas', 'is', 'absolutely', 'necessary', '.'], ['Without', 'it', ',', 'local', 'authorities', 'would', 'be', 'unable', 'to', 'plan', 'services', ',', 'target', 'resources', 'and', 'measure', 'performance', 'effectively', '.'], ['The', 'cost', 'to', 'the', 'country', 'would', 'exceed', 'the', 'cost', 'of', 'a', 'decennial', 'census', '.'], ['Would', 'suggest', 'that', 'both', 'options', 'should', 'be', 'carried', 'out', ',', 'if', 'possible', ',', 'rather', 'than', 'one', 'or', 'the', 'other', '.'], ['That', 'way', ',', 'we', 'get', 'the', 'accurate', 'picture', 'every', 'ten', 'years', ',', 'and', 'a', 'good/', 'useful', 'indication', 'of', 'trends', 'throughout', 'the', 'in-between', 'periods', '.'], ['If', 'it', 'has', 'to', 'be', 'a', 'choice', 'of', 'just', 'one', 'or', 'the', 'other', ',', 'then', 'a', 'detailed', '10', 'year', 'census', 'would', 'is', 'preferred', '.'], ['The', 'need', 'for', 'accurate', ',', 'precise', 'and', 'regular', 'demographic', 'data', 'is', 'great', 'within', 'large', 'urban', '/', 'metropolitan', 'areas', 'such', 'as', 'Salford', 'and', 'Greater', 'Manchester', 'where', 'the', 'scale', 'and', 'pace', 'of', 'demographic', 'change', 'is', 'substantial', 'and', 'swift', '.'], ['Welfare', 'reform', 'and', 'other', 'changes', 'mean', 'that', 'public', 'services', 'to', 'better', 'identify', 'and', 'target', 'those', 'who', 'are', 'in', 'greatest', 'need', '.'], ['The', 'ability', 'to', 'do', 'that', 'would', 'be', 'severely', 'hampered', 'is', 'detailed', 'small', 'area', 'population', 'data', 'were', 'not', 'available', '.'], ['Output', 'from', 'the', 'decennial', 'census', 'is', 'needed', 'quickly', '.'], ['Suggest', 'that', 'ONS', 'produce', 'fewer', 'research', 'reports', 'in', 'favour', 'of', 'faster', 'data', 'processing', 'and', 'publication', '.'], ['Administrative', 'sources', 'should', 'be', 'used', 'to', 'provide', 'better', 'and', 'more', 'frequent', 'information', 'on', 'deaths', ',', 'school', 'age', 'children', ',', 'sub-national', 'population', 'projections', ',', 'household', 'estimates', 'and', 'projections', 'by', 'household', 'type', '/', 'size', ',']]]\n"
     ]
    }
   ],
   "source": [
    "print(cons1_df.iloc[:, test1_idx]) \n",
    "print([type(a) for a in cons1_df.iloc[:, test1_idx]])\n",
    "print(word_tokenise_answer(cons1_df, test1_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cons1_df.loc[:, 'test2'] = word_tokenise_answer(cons1_df, test1_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test2_idx = cons1_df.columns.get_loc('test2')      #74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[print(w) for w in cons1_df.iloc[:, test2_idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alessia/anaconda3/lib/python3.6/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "# Define function to calculate polarity score for the answers in our dataset\n",
    "\n",
    "# import key modules\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "from numpy import nan\n",
    "    \n",
    "\n",
    "def get_sentiment_score(data, col_ind, score_type = 'compound') :\n",
    "    \"\"\" \n",
    "    \n",
    "    Calculate sentiment analysis score (score_type: 'compound' default, 'pos', 'neg')\n",
    "    for the values in the specified dataframe column.\n",
    "    \n",
    "    Return a list of scores, one score for each sentence in the column cell.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # empty list collector of scores\n",
    "    sentiment_bag = []\n",
    "    \n",
    "    for answer in data.iloc[:, col_ind] :\n",
    "        \n",
    "        #print(len(answer))\n",
    "        \n",
    "        # no answer was provided, return NA\n",
    "        if not answer : \n",
    "            sentiment_bag.append(nan)\n",
    "        \n",
    "        # answer is made of only 1 sentence    \n",
    "        elif len(answer) == 1 :\n",
    "            sentiment_bag.append(analyser.polarity_scores(answer)[score_type])\n",
    "        \n",
    "        # answer contains more than one sentence\n",
    "        elif len(answer) > 1 :\n",
    "            sentiment_bag.append([analyser.polarity_scores(s)[score_type] for s in answer])\n",
    "    \n",
    "    return(sentiment_bag)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[nan,\n",
       " nan,\n",
       " nan,\n",
       " [0.0, -0.4585],\n",
       " [0.0,\n",
       "  0.3818,\n",
       "  0.0,\n",
       "  0.4404,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.4404,\n",
       "  0.0,\n",
       "  0.8481,\n",
       "  0.7964,\n",
       "  -0.1779,\n",
       "  0.0,\n",
       "  0.4404,\n",
       "  0.4404]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "get_sentiment_score(cons1_df, test1_idx, 'compound')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer after sent-tokenisation, before word-tokenisation\n",
    "#[print(list(s)) for s in cons1_df.iloc[3:, test1_idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#[print(str(s)) for s in sent_tokenise_answer(cons1_df, idx_Q1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "nan\n",
      "nan\n",
      "[0.0, -0.4585]\n",
      "[0.0, 0.3818, 0.0, 0.4404, 0.0, 0.0, 0.4404, 0.0, 0.8481, 0.7964, -0.1779, 0.0, 0.4404, 0.4404]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(result) for result in get_sentiment_score(cons1_df, test1_idx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan, nan, nan, -0.22925000000000001, 0.25785714285714284]\n",
      "[nan, nan, nan, -0.22925000000000001, 0.19089999999999999]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alessia/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py:4016: RuntimeWarning: Invalid value encountered in median\n",
      "  r = func(a, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print([mean(np.array(result)) for result in get_sentiment_score(cons1_df, test1_idx)])\n",
    "print([median(np.array(result)) for result in get_sentiment_score(cons1_df, test1_idx)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     2\n",
       "4    14\n",
       "Name: test2, dtype: int64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#[print(w) for w in cons1_df.iloc[:, test2_idx]];\n",
    "[print(len(w)) for w in cons1_df.iloc[:, test2_idx]]    # count number of senences in each answer\n",
    "cons1_df.iloc[:, test2_idx].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to ....\n",
    "\n",
    "import string\n",
    "\n",
    "def break_words(answer_col, compound_symbol = '-') :\n",
    "    \"\"\"\n",
    "    Break words that are of the compound form word1<symbol>word2 into the constituting words, then remove empty strings. \n",
    "    \n",
    "    Default compund symbol = '-'\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # empty list collector\n",
    "    tokens_bag = []\n",
    "    \n",
    "    for answer in answer_col :   \n",
    "        \n",
    "        # no answer was provided, return empty string\n",
    "        if not answer : \n",
    "            tokens_bag.append(\"\")\n",
    "            \n",
    "        # an answer was provided       \n",
    "        else :\n",
    "            \n",
    "            print('No. of sentence in the answer = ' + str(len(answer)))\n",
    "            \n",
    "            \n",
    "            # empty collector to make sure we keep the sentences within an answer as separate lists\n",
    "            words_in_s = []\n",
    "            \n",
    "            for sent in answer :\n",
    "                \n",
    "                # empty collector for words within one sentence\n",
    "                words = []\n",
    "                \n",
    "                # 1. break words that are of the form word1-word2 into constituting words\n",
    "            \n",
    "                for w in sent :\n",
    "                \n",
    "                    if compound_symbol in w :\n",
    "                    \n",
    "                        words.extend(w.split(compound_symbol))\n",
    "                    \n",
    "                    else :\n",
    "                    \n",
    "                        words.append(w)\n",
    "                    \n",
    "                    # 2. Remove empty strings\n",
    "                    words = list(filter(None, words))\n",
    "                    \n",
    "                words_in_s.append(words)\n",
    "\n",
    "            tokens_bag.append(words_in_s)\n",
    "    \n",
    "    return(tokens_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     2\n",
       "4    14\n",
       "Name: test2, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cons1_df.iloc[:, test2_idx].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of sentence in the answer = 2\n",
      "No. of sentence in the answer = 14\n"
     ]
    }
   ],
   "source": [
    "break_words(cons1_df.iloc[:, test2_idx]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = pd.Series([\"\", 'I love double-cream ice-cream', 'I hate fudge. But, I like caramel', 'Pseudo-science. I -care'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I love double-cream ice-cream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I hate fudge. But, I like caramel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pseudo-science. I -care</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                text\n",
       "0                                   \n",
       "1      I love double-cream ice-cream\n",
       "2  I hate fudge. But, I like caramel\n",
       "3            Pseudo-science. I -care"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_df = pd.DataFrame(text)\n",
    "dummy_df.columns = ['text']\n",
    "dummy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                     \n",
      "1        I love double-cream ice-cream\n",
      "2    I hate fudge. But, I like caramel\n",
      "3              Pseudo-science. I -care\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(dummy_df['text'])\n",
    "dummy_df['text1'] = sent_tokenise_answer(dummy_df, 0)\n",
    "dummy_df['text2'] = word_tokenise_answer(dummy_df, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of sentence in the answer = 2\n",
      "No. of sentence in the answer = 14\n"
     ]
    }
   ],
   "source": [
    "break_words(cons1_df['test2']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                                   []\n",
      "1                 [[I, love, double-cream, ice-cream]]\n",
      "2    [[I, hate, fudge, .], [But, ,, I, like, caramel]]\n",
      "3                    [[Pseudo-science, .], [I, -care]]\n",
      "Name: text2, dtype: object\n",
      "No. of sentence in the answer = 1\n",
      "No. of sentence in the answer = 2\n",
      "No. of sentence in the answer = 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['',\n",
       " [['I', 'love', 'double', 'cream', 'ice', 'cream']],\n",
       " [['I', 'hate', 'fudge', '.'], ['But', ',', 'I', 'like', 'caramel']],\n",
       " [['Pseudo', 'science', '.'], ['I', 'care']]]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dummy_df['text2'])\n",
    "break_words(dummy_df['text2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define functions to replace contracted negative forms of auxiliary verbs with negation, remove specified stop-words, \n",
    "\n",
    "import string\n",
    "\n",
    "def remove_stopwords(answer_col, stopwords_list, keep_neg = True) :\n",
    "    \"\"\"\n",
    "    Replace contracted negative forms of auxiliary verbs with negation, remove specified stop-words. \n",
    "    \n",
    "    Default keep_neg = True\n",
    "    \"\"\"\n",
    "    \n",
    "    # empty list collector\n",
    "    tokens_bag = []\n",
    "    \n",
    "    \n",
    "    if keep_neg :       # keep negations in\n",
    "        \n",
    "        stopwords_list = [w for w in stopwords_list if not w in ['no', 'nor', 'not', 'only', 'up', 'down', 'further', 'too', 'against']]\n",
    "             \n",
    "            \n",
    "    for answer in answer_col :   \n",
    "        \n",
    "        # no answer was provided, return empty string\n",
    "        if not answer : \n",
    "            tokens_bag.append(\"\")\n",
    "            \n",
    "        # an answer was provided       \n",
    "        else :\n",
    "            \n",
    "            print('No. of sentence in the answer = ' + str(len(answer)))\n",
    "            \n",
    "            # empty collector to make sure we keep the sentences within an answer as separate lists\n",
    "            sep_sents = []\n",
    "            \n",
    "            for sent in answer :\n",
    "                \n",
    "                if keep_neg :       # keep negations in\n",
    "                    \n",
    "                    for w in sent :\n",
    "                        \n",
    "                        if w in [\"don't\", \"didn\", \"didn't\", \"doesn\", \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", \n",
    "                                 'haven', \"haven't\", 'isn', \"isn't\", 'mightn', \"mightn't\", 'mustn', \"mustn't\", \n",
    "                                 'needn', \"needn't\", \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \n",
    "                                 \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\", 'aren', \"aren't\", 'couldn', \n",
    "                                 \"couldn't\"] :\n",
    "                            \n",
    "                            w = 'not'\n",
    "                        \n",
    "                        else :\n",
    "                        \n",
    "                            w = w\n",
    "                        \n",
    "                # filter out stop words from each answer\n",
    "                new_sent = [w for w in sent if not w in stopwords_list]\n",
    "                \n",
    "                # collect each sentence as a (separate) list of words\n",
    "                sep_sents.append(new_sent)\n",
    "                \n",
    "            tokens_bag.append(sep_sents)\n",
    "            \n",
    "    return(tokens_bag)\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'compound': -0.5216, 'neg': 0.771, 'neu': 0.229, 'pos': 0.0},\n",
       " {'compound': 0.6369, 'neg': 0.0, 'neu': 0.192, 'pos': 0.808},\n",
       " {'compound': 0.6369, 'neg': 0.0, 'neu': 0.0, 'pos': 1.0},\n",
       " {'compound': 0.6369, 'neg': 0.0, 'neu': 0.192, 'pos': 0.808},\n",
       " {'compound': 0.6369, 'neg': 0.0, 'neu': 0.192, 'pos': 0.808},\n",
       " {'compound': 0.3612, 'neg': 0.0, 'neu': 0.0, 'pos': 1.0},\n",
       " {'compound': 0.3612, 'neg': 0.0, 'neu': 0.286, 'pos': 0.714},\n",
       " {'compound': 0.0, 'neg': 0.0, 'neu': 1.0, 'pos': 0.0},\n",
       " {'compound': 0.0, 'neg': 0.0, 'neu': 1.0, 'pos': 0.0}]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[analyser.polarity_scores(aux) for aux in [\"not love\", 'must love', 'love', 'could love', 'would love', 'agree', 'could agree', 'might', 'need']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'compound': 0.0, 'neg': 0.0, 'neu': 1.0, 'pos': 0.0},\n",
       " {'compound': 0.0, 'neg': 0.0, 'neu': 1.0, 'pos': 0.0},\n",
       " {'compound': 0.0, 'neg': 0.0, 'neu': 1.0, 'pos': 0.0},\n",
       " {'compound': 0.0, 'neg': 0.0, 'neu': 1.0, 'pos': 0.0}]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[analyser.polarity_scores(aux) for aux in [\"up\", 'down', 'further', 'I am against the proposal']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                                   []\n",
      "1                 [[I, love, double-cream, ice-cream]]\n",
      "2    [[I, hate, fudge, .], [But, ,, I, like, caramel]]\n",
      "3                    [[Pseudo-science, .], [I, -care]]\n",
      "Name: text2, dtype: object\n",
      "No. of sentence in the answer = 1\n",
      "No. of sentence in the answer = 2\n",
      "No. of sentence in the answer = 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['',\n",
       " [['I', 'love', 'double-cream', 'ice-cream']],\n",
       " [['I', 'hate', 'fudge', '.'], ['But', ',', 'I', 'like', 'caramel']],\n",
       " [['Pseudo-science', '.'], ['I', '-care']]]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "print(dummy_df['text2'])\n",
    "remove_stopwords(dummy_df['text2'], stopwords_list=stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
