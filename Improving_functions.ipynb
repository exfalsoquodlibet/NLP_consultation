{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to sentence-tokenise answers \n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import pandas as pd\n",
    "\n",
    "def sent_tokenise_answer(data, col_ind) :\n",
    "    \n",
    "    \"\"\" Function to sentence-tokenise answers. Return a list of lists that contain sentences as strings.\n",
    "        \n",
    "        data = name of the dataframe\n",
    "        col_ind = index of the column that contains the texts to be sentence-tokenised\n",
    "    \"\"\"\n",
    "    \n",
    "    sents_collector = []\n",
    "    \n",
    "    for answer in data.iloc[:, col_ind] :\n",
    "        \n",
    "        #if no answer was provided, return empty string list\n",
    "        if pd.isnull(answer) :\n",
    "            sents_collector.append(list(\"\"))\n",
    "            \n",
    "        # an answer was provided    \n",
    "        else :\n",
    "            sents_collector.append(sent_tokenize(answer))\n",
    "            \n",
    "    return(sents_collector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cons1_df = pd.read_csv(\"/Users/alessia/Documents/DataScience/NLP_Project/Outputs/cons1_lemmas_df.csv\", nrows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get column index of questions\n",
    "idx_Q1 = cons1_df.columns.get_loc(str([col for col in cons1_df if 'census methods' in str(col)][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_Q1     #42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to word-tokenise sentences \n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def word_tokenise_answer(data, col_ind) :\n",
    "    \n",
    "    \"\"\" Function to word-tokenise answers' sentences. Return a list of lists of words as strings. \n",
    "        Required input, a list of lists containing sentences as strings.\n",
    "        \n",
    "        data = name of the dataframe\n",
    "        col_ind = index of the column that contains the list of sentences to be word-tokenised\n",
    "    \"\"\"\n",
    "    \n",
    "    sents_collector = []\n",
    "    \n",
    "    for answer in data.iloc[:, col_ind] :\n",
    "        \n",
    "        #check\n",
    "        #if not answer :\n",
    "        #    print(\"answer is Null\")\n",
    "        \n",
    "        #if no answer was provided, return empty string list\n",
    "        if not answer:\n",
    "            sents_collector.append(list(\"\"))\n",
    "            \n",
    "        # an answer was provided    \n",
    "        else :\n",
    "            \n",
    "            words_collector = []\n",
    "            \n",
    "            for sent in answer :\n",
    "                words_collector.append(word_tokenize(sent))\n",
    "                \n",
    "            sents_collector.append(words_collector)\n",
    "            \n",
    "    return(sents_collector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[str, str, str, str, str, str, str, str, str, str, str, str, str, str]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[type(s) for s in sent_tokenise_answer(cons1_df, idx_Q1)[4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cons1_df.loc[:, 'test1'] = sent_tokenise_answer(cons1_df, idx_Q1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test1_idx = cons1_df.columns.get_loc('test1')      #73"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                   []\n",
       "1                                                   []\n",
       "2                                                   []\n",
       "3    [Moving to a primarily online census: an inevi...\n",
       "4    [A regular full population census is absolutel...\n",
       "Name: test1, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cons1_df.loc[:, 'test1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                   []\n",
       "1                                                   []\n",
       "2                                                   []\n",
       "3    [Moving to a primarily online census: an inevi...\n",
       "4    [A regular full population census is absolutel...\n",
       "Name: test1, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cons1_df.iloc[:, test1_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                                   []\n",
      "1                                                   []\n",
      "2                                                   []\n",
      "3    [Moving to a primarily online census: an inevi...\n",
      "4    [A regular full population census is absolutel...\n",
      "Name: test1, dtype: object\n",
      "[<class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>, <class 'list'>]\n",
      "[[], [], [], [['Moving', 'to', 'a', 'primarily', 'online', 'census', ':', 'an', 'inevitable', 'and', 'necessary', 'evolution', 'of', 'the', 'existing', 'approach', '.'], ['Admin', 'data', 'and', 'surveys', ':', 'an', 'unknown', 'quantity', ',', 'dependent', 'on', 'the', 'quality', 'of', 'admin', 'data', ',', 'and', 'not', 'clear', 'how', 'well', 'it', 'would', 'fulfil', 'the', 'primary', 'aim', 'of', 'a', 'census', ':', 'to', 'produce', 'an', 'accurate', 'and', 'independent', 'estimate', 'of', 'the', 'size', 'and', 'composition', 'of', 'the', 'population', '.']], [['A', 'regular', 'full', 'population', 'census', 'is', 'absolutely', 'necessary', '.'], ['It', 'is', 'the', 'only', 'way', 'to', 'ensure', 'that', 'all', 'population', 'and', 'social', 'statistical', 'estimates', 'and', 'projections', 'are', 'grounded', 'in', 'reality', '.'], ['Data', 'for', 'small', 'areas', 'is', 'absolutely', 'necessary', '.'], ['Without', 'it', ',', 'local', 'authorities', 'would', 'be', 'unable', 'to', 'plan', 'services', ',', 'target', 'resources', 'and', 'measure', 'performance', 'effectively', '.'], ['The', 'cost', 'to', 'the', 'country', 'would', 'exceed', 'the', 'cost', 'of', 'a', 'decennial', 'census', '.'], ['Would', 'suggest', 'that', 'both', 'options', 'should', 'be', 'carried', 'out', ',', 'if', 'possible', ',', 'rather', 'than', 'one', 'or', 'the', 'other', '.'], ['That', 'way', ',', 'we', 'get', 'the', 'accurate', 'picture', 'every', 'ten', 'years', ',', 'and', 'a', 'good/', 'useful', 'indication', 'of', 'trends', 'throughout', 'the', 'in-between', 'periods', '.'], ['If', 'it', 'has', 'to', 'be', 'a', 'choice', 'of', 'just', 'one', 'or', 'the', 'other', ',', 'then', 'a', 'detailed', '10', 'year', 'census', 'would', 'is', 'preferred', '.'], ['The', 'need', 'for', 'accurate', ',', 'precise', 'and', 'regular', 'demographic', 'data', 'is', 'great', 'within', 'large', 'urban', '/', 'metropolitan', 'areas', 'such', 'as', 'Salford', 'and', 'Greater', 'Manchester', 'where', 'the', 'scale', 'and', 'pace', 'of', 'demographic', 'change', 'is', 'substantial', 'and', 'swift', '.'], ['Welfare', 'reform', 'and', 'other', 'changes', 'mean', 'that', 'public', 'services', 'to', 'better', 'identify', 'and', 'target', 'those', 'who', 'are', 'in', 'greatest', 'need', '.'], ['The', 'ability', 'to', 'do', 'that', 'would', 'be', 'severely', 'hampered', 'is', 'detailed', 'small', 'area', 'population', 'data', 'were', 'not', 'available', '.'], ['Output', 'from', 'the', 'decennial', 'census', 'is', 'needed', 'quickly', '.'], ['Suggest', 'that', 'ONS', 'produce', 'fewer', 'research', 'reports', 'in', 'favour', 'of', 'faster', 'data', 'processing', 'and', 'publication', '.'], ['Administrative', 'sources', 'should', 'be', 'used', 'to', 'provide', 'better', 'and', 'more', 'frequent', 'information', 'on', 'deaths', ',', 'school', 'age', 'children', ',', 'sub-national', 'population', 'projections', ',', 'household', 'estimates', 'and', 'projections', 'by', 'household', 'type', '/', 'size', ',']]]\n"
     ]
    }
   ],
   "source": [
    "print(cons1_df.iloc[:, test1_idx]) \n",
    "print([type(a) for a in cons1_df.iloc[:, test1_idx]])\n",
    "print(word_tokenise_answer(cons1_df, test1_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cons1_df.loc[:, 'test2'] = word_tokenise_answer(cons1_df, test1_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test2_idx = cons1_df.columns.get_loc('test2')      #74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "[['Moving', 'to', 'a', 'primarily', 'online', 'census', ':', 'an', 'inevitable', 'and', 'necessary', 'evolution', 'of', 'the', 'existing', 'approach', '.'], ['Admin', 'data', 'and', 'surveys', ':', 'an', 'unknown', 'quantity', ',', 'dependent', 'on', 'the', 'quality', 'of', 'admin', 'data', ',', 'and', 'not', 'clear', 'how', 'well', 'it', 'would', 'fulfil', 'the', 'primary', 'aim', 'of', 'a', 'census', ':', 'to', 'produce', 'an', 'accurate', 'and', 'independent', 'estimate', 'of', 'the', 'size', 'and', 'composition', 'of', 'the', 'population', '.']]\n",
      "[['A', 'regular', 'full', 'population', 'census', 'is', 'absolutely', 'necessary', '.'], ['It', 'is', 'the', 'only', 'way', 'to', 'ensure', 'that', 'all', 'population', 'and', 'social', 'statistical', 'estimates', 'and', 'projections', 'are', 'grounded', 'in', 'reality', '.'], ['Data', 'for', 'small', 'areas', 'is', 'absolutely', 'necessary', '.'], ['Without', 'it', ',', 'local', 'authorities', 'would', 'be', 'unable', 'to', 'plan', 'services', ',', 'target', 'resources', 'and', 'measure', 'performance', 'effectively', '.'], ['The', 'cost', 'to', 'the', 'country', 'would', 'exceed', 'the', 'cost', 'of', 'a', 'decennial', 'census', '.'], ['Would', 'suggest', 'that', 'both', 'options', 'should', 'be', 'carried', 'out', ',', 'if', 'possible', ',', 'rather', 'than', 'one', 'or', 'the', 'other', '.'], ['That', 'way', ',', 'we', 'get', 'the', 'accurate', 'picture', 'every', 'ten', 'years', ',', 'and', 'a', 'good/', 'useful', 'indication', 'of', 'trends', 'throughout', 'the', 'in-between', 'periods', '.'], ['If', 'it', 'has', 'to', 'be', 'a', 'choice', 'of', 'just', 'one', 'or', 'the', 'other', ',', 'then', 'a', 'detailed', '10', 'year', 'census', 'would', 'is', 'preferred', '.'], ['The', 'need', 'for', 'accurate', ',', 'precise', 'and', 'regular', 'demographic', 'data', 'is', 'great', 'within', 'large', 'urban', '/', 'metropolitan', 'areas', 'such', 'as', 'Salford', 'and', 'Greater', 'Manchester', 'where', 'the', 'scale', 'and', 'pace', 'of', 'demographic', 'change', 'is', 'substantial', 'and', 'swift', '.'], ['Welfare', 'reform', 'and', 'other', 'changes', 'mean', 'that', 'public', 'services', 'to', 'better', 'identify', 'and', 'target', 'those', 'who', 'are', 'in', 'greatest', 'need', '.'], ['The', 'ability', 'to', 'do', 'that', 'would', 'be', 'severely', 'hampered', 'is', 'detailed', 'small', 'area', 'population', 'data', 'were', 'not', 'available', '.'], ['Output', 'from', 'the', 'decennial', 'census', 'is', 'needed', 'quickly', '.'], ['Suggest', 'that', 'ONS', 'produce', 'fewer', 'research', 'reports', 'in', 'favour', 'of', 'faster', 'data', 'processing', 'and', 'publication', '.'], ['Administrative', 'sources', 'should', 'be', 'used', 'to', 'provide', 'better', 'and', 'more', 'frequent', 'information', 'on', 'deaths', ',', 'school', 'age', 'children', ',', 'sub-national', 'population', 'projections', ',', 'household', 'estimates', 'and', 'projections', 'by', 'household', 'type', '/', 'size', ',']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(w) for w in cons1_df.iloc[:, test2_idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alessia/anaconda3/lib/python3.6/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "# Define function to calculate polarity score for the answers in our dataset\n",
    "\n",
    "# import key modules\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "from numpy import nan\n",
    "    \n",
    "\n",
    "def get_sentiment_score(data, col_ind, score_type = 'compound') :\n",
    "    \"\"\" \n",
    "    \n",
    "    Calculate sentiment analysis score (score_type: 'compound' default, 'pos', 'neg')\n",
    "    for the values in the specified dataframe column.\n",
    "    \n",
    "    Return a list of scores, one score for each sentence in the column cell.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # empty list collector of scores\n",
    "    sentiment_bag = []\n",
    "    \n",
    "    for answer in data.iloc[:, col_ind] :\n",
    "        \n",
    "        #print(len(answer))\n",
    "        \n",
    "        # no answer was provided, return NA\n",
    "        if not answer : \n",
    "            sentiment_bag.append(nan)\n",
    "        \n",
    "        # answer is made of only 1 sentence    \n",
    "        elif len(answer) == 1 :\n",
    "            sentiment_bag.append(analyser.polarity_scores(answer)[score_type])\n",
    "        \n",
    "        # answer contains more than one sentence\n",
    "        elif len(answer) > 1 :\n",
    "            sentiment_bag.append([analyser.polarity_scores(s)[score_type] for s in answer])\n",
    "    \n",
    "    return(sentiment_bag)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[nan,\n",
       " nan,\n",
       " nan,\n",
       " [0.0, -0.4585],\n",
       " [0.0,\n",
       "  0.3818,\n",
       "  0.0,\n",
       "  0.4404,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.4404,\n",
       "  0.0,\n",
       "  0.8481,\n",
       "  0.7964,\n",
       "  -0.1779,\n",
       "  0.0,\n",
       "  0.4404,\n",
       "  0.4404]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "get_sentiment_score(cons1_df, test1_idx, 'compound')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Moving to a primarily online census: an inevitable and necessary evolution of the existing approach.', 'Admin data and surveys: an unknown quantity, dependent on the quality of admin data, and not clear how well it would fulfil the primary aim of a census: to produce an accurate and independent estimate of the size and composition of the population.']\n",
      "['A regular full population census is absolutely necessary.', 'It is the only way to ensure that all population and social statistical estimates and projections are grounded in reality.', 'Data for small areas is absolutely necessary.', 'Without it, local authorities would be unable to plan services, target resources and measure performance effectively.', 'The cost to the country would exceed the cost of a decennial census.', 'Would suggest that both options should be carried out, if possible, rather than one or the other.', 'That way, we get the accurate picture every ten years, and a good/ useful indication of trends throughout the in-between periods.', 'If it has to be a choice of just one or the other, then a detailed 10 year census would is preferred.', 'The need for accurate, precise and regular demographic data is great within large urban / metropolitan areas such as Salford and Greater Manchester where the scale and pace of demographic change is substantial and swift.', 'Welfare reform and other changes mean that public services to better identify and target those who are in greatest need.', 'The ability to do that would be severely hampered is detailed small area population data were not available.', 'Output from the decennial census is needed quickly.', 'Suggest that ONS produce fewer research reports in favour of faster data processing and publication.', 'Administrative sources should be used to provide better and more frequent information on deaths, school age children, sub-national population projections, household estimates and projections by household type / size,']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# answer after sent-tokenisation, before word-tokenisation\n",
    "[print(list(s)) for s in cons1_df.iloc[3:, test1_idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "['Moving to a primarily online census: an inevitable and necessary evolution of the existing approach.', 'Admin data and surveys: an unknown quantity, dependent on the quality of admin data, and not clear how well it would fulfil the primary aim of a census: to produce an accurate and independent estimate of the size and composition of the population.']\n",
      "['A regular full population census is absolutely necessary.', 'It is the only way to ensure that all population and social statistical estimates and projections are grounded in reality.', 'Data for small areas is absolutely necessary.', 'Without it, local authorities would be unable to plan services, target resources and measure performance effectively.', 'The cost to the country would exceed the cost of a decennial census.', 'Would suggest that both options should be carried out, if possible, rather than one or the other.', 'That way, we get the accurate picture every ten years, and a good/ useful indication of trends throughout the in-between periods.', 'If it has to be a choice of just one or the other, then a detailed 10 year census would is preferred.', 'The need for accurate, precise and regular demographic data is great within large urban / metropolitan areas such as Salford and Greater Manchester where the scale and pace of demographic change is substantial and swift.', 'Welfare reform and other changes mean that public services to better identify and target those who are in greatest need.', 'The ability to do that would be severely hampered is detailed small area population data were not available.', 'Output from the decennial census is needed quickly.', 'Suggest that ONS produce fewer research reports in favour of faster data processing and publication.', 'Administrative sources should be used to provide better and more frequent information on deaths, school age children, sub-national population projections, household estimates and projections by household type / size,']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(str(s)) for s in sent_tokenise_answer(cons1_df, idx_Q1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "nan\n",
      "nan\n",
      "[0.0, -0.4585]\n",
      "[0.0, 0.3818, 0.0, 0.4404, 0.0, 0.0, 0.4404, 0.0, 0.8481, 0.7964, -0.1779, 0.0, 0.4404, 0.4404]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(result) for result in get_sentiment_score(cons1_df, test1_idx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan, nan, nan, -0.22925000000000001, 0.25785714285714284]\n",
      "[nan, nan, nan, -0.22925000000000001, 0.19089999999999999]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alessia/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py:4016: RuntimeWarning: Invalid value encountered in median\n",
      "  r = func(a, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print([mean(np.array(result)) for result in get_sentiment_score(cons1_df, test1_idx)])\n",
    "print([median(np.array(result)) for result in get_sentiment_score(cons1_df, test1_idx)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "[['Moving', 'to', 'a', 'primarily', 'online', 'census', ':', 'an', 'inevitable', 'and', 'necessary', 'evolution', 'of', 'the', 'existing', 'approach', '.'], ['Admin', 'data', 'and', 'surveys', ':', 'an', 'unknown', 'quantity', ',', 'dependent', 'on', 'the', 'quality', 'of', 'admin', 'data', ',', 'and', 'not', 'clear', 'how', 'well', 'it', 'would', 'fulfil', 'the', 'primary', 'aim', 'of', 'a', 'census', ':', 'to', 'produce', 'an', 'accurate', 'and', 'independent', 'estimate', 'of', 'the', 'size', 'and', 'composition', 'of', 'the', 'population', '.']]\n",
      "[['A', 'regular', 'full', 'population', 'census', 'is', 'absolutely', 'necessary', '.'], ['It', 'is', 'the', 'only', 'way', 'to', 'ensure', 'that', 'all', 'population', 'and', 'social', 'statistical', 'estimates', 'and', 'projections', 'are', 'grounded', 'in', 'reality', '.'], ['Data', 'for', 'small', 'areas', 'is', 'absolutely', 'necessary', '.'], ['Without', 'it', ',', 'local', 'authorities', 'would', 'be', 'unable', 'to', 'plan', 'services', ',', 'target', 'resources', 'and', 'measure', 'performance', 'effectively', '.'], ['The', 'cost', 'to', 'the', 'country', 'would', 'exceed', 'the', 'cost', 'of', 'a', 'decennial', 'census', '.'], ['Would', 'suggest', 'that', 'both', 'options', 'should', 'be', 'carried', 'out', ',', 'if', 'possible', ',', 'rather', 'than', 'one', 'or', 'the', 'other', '.'], ['That', 'way', ',', 'we', 'get', 'the', 'accurate', 'picture', 'every', 'ten', 'years', ',', 'and', 'a', 'good/', 'useful', 'indication', 'of', 'trends', 'throughout', 'the', 'in-between', 'periods', '.'], ['If', 'it', 'has', 'to', 'be', 'a', 'choice', 'of', 'just', 'one', 'or', 'the', 'other', ',', 'then', 'a', 'detailed', '10', 'year', 'census', 'would', 'is', 'preferred', '.'], ['The', 'need', 'for', 'accurate', ',', 'precise', 'and', 'regular', 'demographic', 'data', 'is', 'great', 'within', 'large', 'urban', '/', 'metropolitan', 'areas', 'such', 'as', 'Salford', 'and', 'Greater', 'Manchester', 'where', 'the', 'scale', 'and', 'pace', 'of', 'demographic', 'change', 'is', 'substantial', 'and', 'swift', '.'], ['Welfare', 'reform', 'and', 'other', 'changes', 'mean', 'that', 'public', 'services', 'to', 'better', 'identify', 'and', 'target', 'those', 'who', 'are', 'in', 'greatest', 'need', '.'], ['The', 'ability', 'to', 'do', 'that', 'would', 'be', 'severely', 'hampered', 'is', 'detailed', 'small', 'area', 'population', 'data', 'were', 'not', 'available', '.'], ['Output', 'from', 'the', 'decennial', 'census', 'is', 'needed', 'quickly', '.'], ['Suggest', 'that', 'ONS', 'produce', 'fewer', 'research', 'reports', 'in', 'favour', 'of', 'faster', 'data', 'processing', 'and', 'publication', '.'], ['Administrative', 'sources', 'should', 'be', 'used', 'to', 'provide', 'better', 'and', 'more', 'frequent', 'information', 'on', 'deaths', ',', 'school', 'age', 'children', ',', 'sub-national', 'population', 'projections', ',', 'household', 'estimates', 'and', 'projections', 'by', 'household', 'type', '/', 'size', ',']]\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     2\n",
       "4    14\n",
       "Name: test2, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(w) for w in cons1_df.iloc[:, test2_idx]];\n",
    "[print(len(w)) for w in cons1_df.iloc[:, test2_idx]]    # count number of senences in each answer\n",
    "cons1_df.iloc[:, test2_idx].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to ....\n",
    "\n",
    "import string\n",
    "\n",
    "def break_words(answer_col, compound_symbol = '-') :\n",
    "    \"\"\"\n",
    "    Break words that are of the compound form word1<symbol>word2 into the constituting words, then remove empty strings. \n",
    "    \n",
    "    Default compunding symbol = '-'\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # empty list collector\n",
    "    tokens_bag = []\n",
    "    \n",
    "    for answer in answer_col :   \n",
    "        \n",
    "        # no answer was provided, return empty string\n",
    "        if not answer : \n",
    "            tokens_bag.append(\"\")\n",
    "            \n",
    "        # an answer was provided       \n",
    "        else :\n",
    "            \n",
    "            print('No. of sentence in the answer = ' + str(len(answer)))\n",
    "            \n",
    "            \n",
    "            # empty collector to make sure we keep the sentences within an answer in separate lists\n",
    "            words_in_s = []\n",
    "            \n",
    "            for sent in answer :\n",
    "                \n",
    "                # empty collector for words within one sentence\n",
    "                words = []\n",
    "                \n",
    "                # 1. break words that are of the form word1-word2 into constituting words\n",
    "            \n",
    "                for w in sent :\n",
    "                \n",
    "                    if compound_symbol in w :\n",
    "                    \n",
    "                        words.extend(w.split(compound_symbol))\n",
    "                    \n",
    "                    else :\n",
    "                    \n",
    "                        words.append(w)\n",
    "                    \n",
    "                    # 2. Remove empty strings\n",
    "                    words = list(filter(None, words))\n",
    "                    \n",
    "                words_in_s.append(words)\n",
    "\n",
    "            tokens_bag.append(words_in_s)\n",
    "    \n",
    "    return(tokens_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     2\n",
       "4    14\n",
       "Name: test2, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cons1_df.iloc[:, test2_idx].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of sentence in the answer = 2\n",
      "No. of sentence in the answer = 14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '',\n",
       " '',\n",
       " [['Moving',\n",
       "   'to',\n",
       "   'a',\n",
       "   'primarily',\n",
       "   'online',\n",
       "   'census',\n",
       "   ':',\n",
       "   'an',\n",
       "   'inevitable',\n",
       "   'and',\n",
       "   'necessary',\n",
       "   'evolution',\n",
       "   'of',\n",
       "   'the',\n",
       "   'existing',\n",
       "   'approach',\n",
       "   '.'],\n",
       "  ['Admin',\n",
       "   'data',\n",
       "   'and',\n",
       "   'surveys',\n",
       "   ':',\n",
       "   'an',\n",
       "   'unknown',\n",
       "   'quantity',\n",
       "   ',',\n",
       "   'dependent',\n",
       "   'on',\n",
       "   'the',\n",
       "   'quality',\n",
       "   'of',\n",
       "   'admin',\n",
       "   'data',\n",
       "   ',',\n",
       "   'and',\n",
       "   'not',\n",
       "   'clear',\n",
       "   'how',\n",
       "   'well',\n",
       "   'it',\n",
       "   'would',\n",
       "   'fulfil',\n",
       "   'the',\n",
       "   'primary',\n",
       "   'aim',\n",
       "   'of',\n",
       "   'a',\n",
       "   'census',\n",
       "   ':',\n",
       "   'to',\n",
       "   'produce',\n",
       "   'an',\n",
       "   'accurate',\n",
       "   'and',\n",
       "   'independent',\n",
       "   'estimate',\n",
       "   'of',\n",
       "   'the',\n",
       "   'size',\n",
       "   'and',\n",
       "   'composition',\n",
       "   'of',\n",
       "   'the',\n",
       "   'population',\n",
       "   '.']],\n",
       " [['A',\n",
       "   'regular',\n",
       "   'full',\n",
       "   'population',\n",
       "   'census',\n",
       "   'is',\n",
       "   'absolutely',\n",
       "   'necessary',\n",
       "   '.'],\n",
       "  ['It',\n",
       "   'is',\n",
       "   'the',\n",
       "   'only',\n",
       "   'way',\n",
       "   'to',\n",
       "   'ensure',\n",
       "   'that',\n",
       "   'all',\n",
       "   'population',\n",
       "   'and',\n",
       "   'social',\n",
       "   'statistical',\n",
       "   'estimates',\n",
       "   'and',\n",
       "   'projections',\n",
       "   'are',\n",
       "   'grounded',\n",
       "   'in',\n",
       "   'reality',\n",
       "   '.'],\n",
       "  ['Data', 'for', 'small', 'areas', 'is', 'absolutely', 'necessary', '.'],\n",
       "  ['Without',\n",
       "   'it',\n",
       "   ',',\n",
       "   'local',\n",
       "   'authorities',\n",
       "   'would',\n",
       "   'be',\n",
       "   'unable',\n",
       "   'to',\n",
       "   'plan',\n",
       "   'services',\n",
       "   ',',\n",
       "   'target',\n",
       "   'resources',\n",
       "   'and',\n",
       "   'measure',\n",
       "   'performance',\n",
       "   'effectively',\n",
       "   '.'],\n",
       "  ['The',\n",
       "   'cost',\n",
       "   'to',\n",
       "   'the',\n",
       "   'country',\n",
       "   'would',\n",
       "   'exceed',\n",
       "   'the',\n",
       "   'cost',\n",
       "   'of',\n",
       "   'a',\n",
       "   'decennial',\n",
       "   'census',\n",
       "   '.'],\n",
       "  ['Would',\n",
       "   'suggest',\n",
       "   'that',\n",
       "   'both',\n",
       "   'options',\n",
       "   'should',\n",
       "   'be',\n",
       "   'carried',\n",
       "   'out',\n",
       "   ',',\n",
       "   'if',\n",
       "   'possible',\n",
       "   ',',\n",
       "   'rather',\n",
       "   'than',\n",
       "   'one',\n",
       "   'or',\n",
       "   'the',\n",
       "   'other',\n",
       "   '.'],\n",
       "  ['That',\n",
       "   'way',\n",
       "   ',',\n",
       "   'we',\n",
       "   'get',\n",
       "   'the',\n",
       "   'accurate',\n",
       "   'picture',\n",
       "   'every',\n",
       "   'ten',\n",
       "   'years',\n",
       "   ',',\n",
       "   'and',\n",
       "   'a',\n",
       "   'good/',\n",
       "   'useful',\n",
       "   'indication',\n",
       "   'of',\n",
       "   'trends',\n",
       "   'throughout',\n",
       "   'the',\n",
       "   'in',\n",
       "   'between',\n",
       "   'periods',\n",
       "   '.'],\n",
       "  ['If',\n",
       "   'it',\n",
       "   'has',\n",
       "   'to',\n",
       "   'be',\n",
       "   'a',\n",
       "   'choice',\n",
       "   'of',\n",
       "   'just',\n",
       "   'one',\n",
       "   'or',\n",
       "   'the',\n",
       "   'other',\n",
       "   ',',\n",
       "   'then',\n",
       "   'a',\n",
       "   'detailed',\n",
       "   '10',\n",
       "   'year',\n",
       "   'census',\n",
       "   'would',\n",
       "   'is',\n",
       "   'preferred',\n",
       "   '.'],\n",
       "  ['The',\n",
       "   'need',\n",
       "   'for',\n",
       "   'accurate',\n",
       "   ',',\n",
       "   'precise',\n",
       "   'and',\n",
       "   'regular',\n",
       "   'demographic',\n",
       "   'data',\n",
       "   'is',\n",
       "   'great',\n",
       "   'within',\n",
       "   'large',\n",
       "   'urban',\n",
       "   '/',\n",
       "   'metropolitan',\n",
       "   'areas',\n",
       "   'such',\n",
       "   'as',\n",
       "   'Salford',\n",
       "   'and',\n",
       "   'Greater',\n",
       "   'Manchester',\n",
       "   'where',\n",
       "   'the',\n",
       "   'scale',\n",
       "   'and',\n",
       "   'pace',\n",
       "   'of',\n",
       "   'demographic',\n",
       "   'change',\n",
       "   'is',\n",
       "   'substantial',\n",
       "   'and',\n",
       "   'swift',\n",
       "   '.'],\n",
       "  ['Welfare',\n",
       "   'reform',\n",
       "   'and',\n",
       "   'other',\n",
       "   'changes',\n",
       "   'mean',\n",
       "   'that',\n",
       "   'public',\n",
       "   'services',\n",
       "   'to',\n",
       "   'better',\n",
       "   'identify',\n",
       "   'and',\n",
       "   'target',\n",
       "   'those',\n",
       "   'who',\n",
       "   'are',\n",
       "   'in',\n",
       "   'greatest',\n",
       "   'need',\n",
       "   '.'],\n",
       "  ['The',\n",
       "   'ability',\n",
       "   'to',\n",
       "   'do',\n",
       "   'that',\n",
       "   'would',\n",
       "   'be',\n",
       "   'severely',\n",
       "   'hampered',\n",
       "   'is',\n",
       "   'detailed',\n",
       "   'small',\n",
       "   'area',\n",
       "   'population',\n",
       "   'data',\n",
       "   'were',\n",
       "   'not',\n",
       "   'available',\n",
       "   '.'],\n",
       "  ['Output',\n",
       "   'from',\n",
       "   'the',\n",
       "   'decennial',\n",
       "   'census',\n",
       "   'is',\n",
       "   'needed',\n",
       "   'quickly',\n",
       "   '.'],\n",
       "  ['Suggest',\n",
       "   'that',\n",
       "   'ONS',\n",
       "   'produce',\n",
       "   'fewer',\n",
       "   'research',\n",
       "   'reports',\n",
       "   'in',\n",
       "   'favour',\n",
       "   'of',\n",
       "   'faster',\n",
       "   'data',\n",
       "   'processing',\n",
       "   'and',\n",
       "   'publication',\n",
       "   '.'],\n",
       "  ['Administrative',\n",
       "   'sources',\n",
       "   'should',\n",
       "   'be',\n",
       "   'used',\n",
       "   'to',\n",
       "   'provide',\n",
       "   'better',\n",
       "   'and',\n",
       "   'more',\n",
       "   'frequent',\n",
       "   'information',\n",
       "   'on',\n",
       "   'deaths',\n",
       "   ',',\n",
       "   'school',\n",
       "   'age',\n",
       "   'children',\n",
       "   ',',\n",
       "   'sub',\n",
       "   'national',\n",
       "   'population',\n",
       "   'projections',\n",
       "   ',',\n",
       "   'household',\n",
       "   'estimates',\n",
       "   'and',\n",
       "   'projections',\n",
       "   'by',\n",
       "   'household',\n",
       "   'type',\n",
       "   '/',\n",
       "   'size',\n",
       "   ',']]]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "break_words(cons1_df.iloc[:, test2_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = pd.Series([\"\", 'I love double-cream ice-cream', 'I hate fudge. But, I like caramel', 'Pseudo-science. I -care'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I love double-cream ice-cream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I hate fudge. But, I like caramel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pseudo-science. I -care</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                text\n",
       "0                                   \n",
       "1      I love double-cream ice-cream\n",
       "2  I hate fudge. But, I like caramel\n",
       "3            Pseudo-science. I -care"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_df = pd.DataFrame(text)\n",
    "dummy_df.columns = ['text']\n",
    "dummy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                     \n",
      "1        I love double-cream ice-cream\n",
      "2    I hate fudge. But, I like caramel\n",
      "3              Pseudo-science. I -care\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(dummy_df['text'])\n",
    "dummy_df['text1'] = sent_tokenise_answer(dummy_df, 0)\n",
    "dummy_df['text2'] = word_tokenise_answer(dummy_df, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of sentence in the answer = 2\n",
      "No. of sentence in the answer = 14\n"
     ]
    }
   ],
   "source": [
    "break_words(cons1_df['test2']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                                   []\n",
      "1                 [[I, love, double-cream, ice-cream]]\n",
      "2    [[I, hate, fudge, .], [But, ,, I, like, caramel]]\n",
      "3                    [[Pseudo-science, .], [I, -care]]\n",
      "Name: text2, dtype: object\n",
      "No. of sentence in the answer = 1\n",
      "No. of sentence in the answer = 2\n",
      "No. of sentence in the answer = 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['',\n",
       " [['I', 'love', 'double', 'cream', 'ice', 'cream']],\n",
       " [['I', 'hate', 'fudge', '.'], ['But', ',', 'I', 'like', 'caramel']],\n",
       " [['Pseudo', 'science', '.'], ['I', 'care']]]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dummy_df['text2'])\n",
    "break_words(dummy_df['text2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
