{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to sentence-tokenise answers \n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import pandas as pd\n",
    "\n",
    "def sent_tokenise_answer(data, col_ind) :\n",
    "    \n",
    "    \"\"\" Function to sentence-tokenise answers. Return a list of lists that contain sentences as strings.\n",
    "        \n",
    "        data = name of the dataframe\n",
    "        col_ind = index of the column that contains the texts to be sentence-tokenised\n",
    "    \"\"\"\n",
    "    \n",
    "    sents_collector = []\n",
    "    \n",
    "    for answer in data.iloc[:, col_ind] :\n",
    "        \n",
    "        #if no answer was provided, return empty string list\n",
    "        if pd.isnull(answer) :\n",
    "            sents_collector.append(list(\"\"))\n",
    "            \n",
    "        # an answer was provided    \n",
    "        else :\n",
    "            sents_collector.append(sent_tokenize(answer))\n",
    "            \n",
    "    return(sents_collector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cons1_df = pd.read_csv(\"/Users/alessia/Documents/DataScience/NLP_Project/Outputs/cons1_lemmas_df.csv\", nrows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get column index of questions\n",
    "idx_Q1 = cons1_df.columns.get_loc(str([col for col in cons1_df if 'census methods' in str(col)][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_Q1     #42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to word-tokenise sentences \n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def word_tokenise_answer(data, col_ind) :\n",
    "    \n",
    "    \"\"\" Function to word-tokenise answers' sentences. Return a list of lists of words as strings. \n",
    "        Required input, a list of lists containing sentences as strings.\n",
    "        \n",
    "        data = name of the dataframe\n",
    "        col_ind = index of the column that contains the list of sentences to be word-tokenised\n",
    "    \"\"\"\n",
    "    \n",
    "    sents_collector = []\n",
    "    \n",
    "    for answer in data.iloc[:, col_ind] :\n",
    "        \n",
    "        words_collector = []\n",
    "        \n",
    "        #if no answer was provided, return empty string list\n",
    "        if not answer:\n",
    "            sents_collector.append(list(\"\"))\n",
    "            \n",
    "        # an answer was provided    \n",
    "        else :\n",
    "            for sent in answer :\n",
    "                words_collector.append(word_tokenize(sent))\n",
    "                \n",
    "        sents_collector.append(words_collector)\n",
    "            \n",
    "    return(sents_collector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[str, str, str, str, str, str, str, str, str, str, str, str, str, str]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[type(s) for s in sent_tokenise_answer(cons1_df, idx_Q1)[4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cons1_df.loc[:, 'test1'] = sent_tokenise_answer(cons1_df, idx_Q1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test1_idx = cons1_df.columns.get_loc('test1')      #73"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                   []\n",
       "1                                                   []\n",
       "2                                                   []\n",
       "3    [Moving to a primarily online census: an inevi...\n",
       "4    [A regular full population census is absolutel...\n",
       "Name: test1, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cons1_df.loc[:, 'test1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                   []\n",
       "1                                                   []\n",
       "2                                                   []\n",
       "3    [Moving to a primarily online census: an inevi...\n",
       "4    [A regular full population census is absolutel...\n",
       "Name: test1, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cons1_df.iloc[:, test1_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [['Moving',\n",
       "   'to',\n",
       "   'a',\n",
       "   'primarily',\n",
       "   'online',\n",
       "   'census',\n",
       "   ':',\n",
       "   'an',\n",
       "   'inevitable',\n",
       "   'and',\n",
       "   'necessary',\n",
       "   'evolution',\n",
       "   'of',\n",
       "   'the',\n",
       "   'existing',\n",
       "   'approach',\n",
       "   '.'],\n",
       "  ['Admin',\n",
       "   'data',\n",
       "   'and',\n",
       "   'surveys',\n",
       "   ':',\n",
       "   'an',\n",
       "   'unknown',\n",
       "   'quantity',\n",
       "   ',',\n",
       "   'dependent',\n",
       "   'on',\n",
       "   'the',\n",
       "   'quality',\n",
       "   'of',\n",
       "   'admin',\n",
       "   'data',\n",
       "   ',',\n",
       "   'and',\n",
       "   'not',\n",
       "   'clear',\n",
       "   'how',\n",
       "   'well',\n",
       "   'it',\n",
       "   'would',\n",
       "   'fulfil',\n",
       "   'the',\n",
       "   'primary',\n",
       "   'aim',\n",
       "   'of',\n",
       "   'a',\n",
       "   'census',\n",
       "   ':',\n",
       "   'to',\n",
       "   'produce',\n",
       "   'an',\n",
       "   'accurate',\n",
       "   'and',\n",
       "   'independent',\n",
       "   'estimate',\n",
       "   'of',\n",
       "   'the',\n",
       "   'size',\n",
       "   'and',\n",
       "   'composition',\n",
       "   'of',\n",
       "   'the',\n",
       "   'population',\n",
       "   '.']],\n",
       " [['A',\n",
       "   'regular',\n",
       "   'full',\n",
       "   'population',\n",
       "   'census',\n",
       "   'is',\n",
       "   'absolutely',\n",
       "   'necessary',\n",
       "   '.'],\n",
       "  ['It',\n",
       "   'is',\n",
       "   'the',\n",
       "   'only',\n",
       "   'way',\n",
       "   'to',\n",
       "   'ensure',\n",
       "   'that',\n",
       "   'all',\n",
       "   'population',\n",
       "   'and',\n",
       "   'social',\n",
       "   'statistical',\n",
       "   'estimates',\n",
       "   'and',\n",
       "   'projections',\n",
       "   'are',\n",
       "   'grounded',\n",
       "   'in',\n",
       "   'reality',\n",
       "   '.'],\n",
       "  ['Data', 'for', 'small', 'areas', 'is', 'absolutely', 'necessary', '.'],\n",
       "  ['Without',\n",
       "   'it',\n",
       "   ',',\n",
       "   'local',\n",
       "   'authorities',\n",
       "   'would',\n",
       "   'be',\n",
       "   'unable',\n",
       "   'to',\n",
       "   'plan',\n",
       "   'services',\n",
       "   ',',\n",
       "   'target',\n",
       "   'resources',\n",
       "   'and',\n",
       "   'measure',\n",
       "   'performance',\n",
       "   'effectively',\n",
       "   '.'],\n",
       "  ['The',\n",
       "   'cost',\n",
       "   'to',\n",
       "   'the',\n",
       "   'country',\n",
       "   'would',\n",
       "   'exceed',\n",
       "   'the',\n",
       "   'cost',\n",
       "   'of',\n",
       "   'a',\n",
       "   'decennial',\n",
       "   'census',\n",
       "   '.'],\n",
       "  ['Would',\n",
       "   'suggest',\n",
       "   'that',\n",
       "   'both',\n",
       "   'options',\n",
       "   'should',\n",
       "   'be',\n",
       "   'carried',\n",
       "   'out',\n",
       "   ',',\n",
       "   'if',\n",
       "   'possible',\n",
       "   ',',\n",
       "   'rather',\n",
       "   'than',\n",
       "   'one',\n",
       "   'or',\n",
       "   'the',\n",
       "   'other',\n",
       "   '.'],\n",
       "  ['That',\n",
       "   'way',\n",
       "   ',',\n",
       "   'we',\n",
       "   'get',\n",
       "   'the',\n",
       "   'accurate',\n",
       "   'picture',\n",
       "   'every',\n",
       "   'ten',\n",
       "   'years',\n",
       "   ',',\n",
       "   'and',\n",
       "   'a',\n",
       "   'good/',\n",
       "   'useful',\n",
       "   'indication',\n",
       "   'of',\n",
       "   'trends',\n",
       "   'throughout',\n",
       "   'the',\n",
       "   'in-between',\n",
       "   'periods',\n",
       "   '.'],\n",
       "  ['If',\n",
       "   'it',\n",
       "   'has',\n",
       "   'to',\n",
       "   'be',\n",
       "   'a',\n",
       "   'choice',\n",
       "   'of',\n",
       "   'just',\n",
       "   'one',\n",
       "   'or',\n",
       "   'the',\n",
       "   'other',\n",
       "   ',',\n",
       "   'then',\n",
       "   'a',\n",
       "   'detailed',\n",
       "   '10',\n",
       "   'year',\n",
       "   'census',\n",
       "   'would',\n",
       "   'is',\n",
       "   'preferred',\n",
       "   '.'],\n",
       "  ['The',\n",
       "   'need',\n",
       "   'for',\n",
       "   'accurate',\n",
       "   ',',\n",
       "   'precise',\n",
       "   'and',\n",
       "   'regular',\n",
       "   'demographic',\n",
       "   'data',\n",
       "   'is',\n",
       "   'great',\n",
       "   'within',\n",
       "   'large',\n",
       "   'urban',\n",
       "   '/',\n",
       "   'metropolitan',\n",
       "   'areas',\n",
       "   'such',\n",
       "   'as',\n",
       "   'Salford',\n",
       "   'and',\n",
       "   'Greater',\n",
       "   'Manchester',\n",
       "   'where',\n",
       "   'the',\n",
       "   'scale',\n",
       "   'and',\n",
       "   'pace',\n",
       "   'of',\n",
       "   'demographic',\n",
       "   'change',\n",
       "   'is',\n",
       "   'substantial',\n",
       "   'and',\n",
       "   'swift',\n",
       "   '.'],\n",
       "  ['Welfare',\n",
       "   'reform',\n",
       "   'and',\n",
       "   'other',\n",
       "   'changes',\n",
       "   'mean',\n",
       "   'that',\n",
       "   'public',\n",
       "   'services',\n",
       "   'to',\n",
       "   'better',\n",
       "   'identify',\n",
       "   'and',\n",
       "   'target',\n",
       "   'those',\n",
       "   'who',\n",
       "   'are',\n",
       "   'in',\n",
       "   'greatest',\n",
       "   'need',\n",
       "   '.'],\n",
       "  ['The',\n",
       "   'ability',\n",
       "   'to',\n",
       "   'do',\n",
       "   'that',\n",
       "   'would',\n",
       "   'be',\n",
       "   'severely',\n",
       "   'hampered',\n",
       "   'is',\n",
       "   'detailed',\n",
       "   'small',\n",
       "   'area',\n",
       "   'population',\n",
       "   'data',\n",
       "   'were',\n",
       "   'not',\n",
       "   'available',\n",
       "   '.'],\n",
       "  ['Output',\n",
       "   'from',\n",
       "   'the',\n",
       "   'decennial',\n",
       "   'census',\n",
       "   'is',\n",
       "   'needed',\n",
       "   'quickly',\n",
       "   '.'],\n",
       "  ['Suggest',\n",
       "   'that',\n",
       "   'ONS',\n",
       "   'produce',\n",
       "   'fewer',\n",
       "   'research',\n",
       "   'reports',\n",
       "   'in',\n",
       "   'favour',\n",
       "   'of',\n",
       "   'faster',\n",
       "   'data',\n",
       "   'processing',\n",
       "   'and',\n",
       "   'publication',\n",
       "   '.'],\n",
       "  ['Administrative',\n",
       "   'sources',\n",
       "   'should',\n",
       "   'be',\n",
       "   'used',\n",
       "   'to',\n",
       "   'provide',\n",
       "   'better',\n",
       "   'and',\n",
       "   'more',\n",
       "   'frequent',\n",
       "   'information',\n",
       "   'on',\n",
       "   'deaths',\n",
       "   ',',\n",
       "   'school',\n",
       "   'age',\n",
       "   'children',\n",
       "   ',',\n",
       "   'sub-national',\n",
       "   'population',\n",
       "   'projections',\n",
       "   ',',\n",
       "   'household',\n",
       "   'estimates',\n",
       "   'and',\n",
       "   'projections',\n",
       "   'by',\n",
       "   'household',\n",
       "   'type',\n",
       "   '/',\n",
       "   'size',\n",
       "   ',']]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenise_answer(cons1_df, test1_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to calculate polarity score for the answers in our dataset\n",
    "\n",
    "# import key modules\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "from numpy import nan\n",
    "    \n",
    "\n",
    "def get_sentiment_score(data, col_ind, score_type = 'compound') :\n",
    "    \"\"\" \n",
    "    \n",
    "    Calculate sentiment analysis score (score_type: 'compound' default, 'positive', 'negative')\n",
    "    for the values in the specified dataframe column.\n",
    "    \n",
    "    Return a list of scores, one score for each sentence in the column cell.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # empty list collector of scores\n",
    "    sentiment_bag = []\n",
    "    \n",
    "    for answer in data.iloc[:, col_ind] :\n",
    "        \n",
    "        #print(len(answer))\n",
    "        \n",
    "        # no answer was provided, return NA\n",
    "        if not answer : \n",
    "            sentiment_bag.append(nan)\n",
    "        \n",
    "        # answer is made of only 1 sentence    \n",
    "        elif len(answer) == 1 :\n",
    "            sentiment_bag.append(analyser.polarity_scores(answer)[score_type])\n",
    "        \n",
    "        # answer contains more than one sentence\n",
    "        elif len(answer) > 1 :\n",
    "            sentiment_bag.append([analyser.polarity_scores(s)[score_type] for s in answer])\n",
    "    \n",
    "    return(sentiment_bag)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[nan,\n",
       " nan,\n",
       " nan,\n",
       " [0.0, -0.4585],\n",
       " [0.0,\n",
       "  0.3818,\n",
       "  0.0,\n",
       "  0.4404,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.4404,\n",
       "  0.0,\n",
       "  0.8481,\n",
       "  0.7964,\n",
       "  -0.1779,\n",
       "  0.0,\n",
       "  0.4404,\n",
       "  0.4404]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "get_sentiment_score(cons1_df, test1_idx, 'compound')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Moving to a primarily online census: an inevitable and necessary evolution of the existing approach.', 'Admin data and surveys: an unknown quantity, dependent on the quality of admin data, and not clear how well it would fulfil the primary aim of a census: to produce an accurate and independent estimate of the size and composition of the population.']\n",
      "['A regular full population census is absolutely necessary.', 'It is the only way to ensure that all population and social statistical estimates and projections are grounded in reality.', 'Data for small areas is absolutely necessary.', 'Without it, local authorities would be unable to plan services, target resources and measure performance effectively.', 'The cost to the country would exceed the cost of a decennial census.', 'Would suggest that both options should be carried out, if possible, rather than one or the other.', 'That way, we get the accurate picture every ten years, and a good/ useful indication of trends throughout the in-between periods.', 'If it has to be a choice of just one or the other, then a detailed 10 year census would is preferred.', 'The need for accurate, precise and regular demographic data is great within large urban / metropolitan areas such as Salford and Greater Manchester where the scale and pace of demographic change is substantial and swift.', 'Welfare reform and other changes mean that public services to better identify and target those who are in greatest need.', 'The ability to do that would be severely hampered is detailed small area population data were not available.', 'Output from the decennial census is needed quickly.', 'Suggest that ONS produce fewer research reports in favour of faster data processing and publication.', 'Administrative sources should be used to provide better and more frequent information on deaths, school age children, sub-national population projections, household estimates and projections by household type / size,']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# answer after sent-tokenisation, before word-tokenisation\n",
    "[print(list(s)) for s in cons1_df.iloc[3:, test1_idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "['Moving to a primarily online census: an inevitable and necessary evolution of the existing approach.', 'Admin data and surveys: an unknown quantity, dependent on the quality of admin data, and not clear how well it would fulfil the primary aim of a census: to produce an accurate and independent estimate of the size and composition of the population.']\n",
      "['A regular full population census is absolutely necessary.', 'It is the only way to ensure that all population and social statistical estimates and projections are grounded in reality.', 'Data for small areas is absolutely necessary.', 'Without it, local authorities would be unable to plan services, target resources and measure performance effectively.', 'The cost to the country would exceed the cost of a decennial census.', 'Would suggest that both options should be carried out, if possible, rather than one or the other.', 'That way, we get the accurate picture every ten years, and a good/ useful indication of trends throughout the in-between periods.', 'If it has to be a choice of just one or the other, then a detailed 10 year census would is preferred.', 'The need for accurate, precise and regular demographic data is great within large urban / metropolitan areas such as Salford and Greater Manchester where the scale and pace of demographic change is substantial and swift.', 'Welfare reform and other changes mean that public services to better identify and target those who are in greatest need.', 'The ability to do that would be severely hampered is detailed small area population data were not available.', 'Output from the decennial census is needed quickly.', 'Suggest that ONS produce fewer research reports in favour of faster data processing and publication.', 'Administrative sources should be used to provide better and more frequent information on deaths, school age children, sub-national population projections, household estimates and projections by household type / size,']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(str(s)) for s in sent_tokenise_answer(cons1_df, idx_Q1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "nan\n",
      "nan\n",
      "[0.0, -0.4585]\n",
      "[0.0, 0.3818, 0.0, 0.4404, 0.0, 0.0, 0.4404, 0.0, 0.8481, 0.7964, -0.1779, 0.0, 0.4404, 0.4404]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(result) for result in get_sentiment_score(cons1_df, test1_idx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan, nan, nan, -0.22925000000000001, 0.25785714285714284]\n",
      "[nan, nan, nan, -0.22925000000000001, 0.19089999999999999]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alessia/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py:4016: RuntimeWarning: Invalid value encountered in median\n",
      "  r = func(a, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print([mean(np.array(result)) for result in get_sentiment_score(cons1_df, test1_idx)])\n",
    "print([median(np.array(result)) for result in get_sentiment_score(cons1_df, test1_idx)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1909\n",
      "0.1909\n"
     ]
    }
   ],
   "source": [
    "print(median(np.array((0.0, 0.3818, 0.0, 0.4404, 0.0, 0.0, 0.4404, 0.0, 0.8481, 0.7964, -0.1779, 0.0, 0.4404, 0.4404))))\n",
    "print(0.3818/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.091, 'neu': 0.909, 'pos': 0.0, 'compound': -0.4585}\n",
      "{'neg': 0.141, 'neu': 0.751, 'pos': 0.108, 'compound': -0.1779}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(analyser.polarity_scores(s)) for s in [\"Admin data and surveys: an unknown quantity, dependent on the quality of admin data, and not clear how well it would fulfil the primary aim of a census: to produce an accurate and independent estimate of the size and composition of the population.\", \"The ability to do that would be severely hampered is detailed small area population data were not available.\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
