{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from operator import itemgetter\n",
    "import string\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk import bigrams\n",
    "from nltk import word_tokenize\n",
    "from nltk.sentiment.util import mark_negation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords as sw\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk import wordpunct_tokenize\n",
    "from nltk import WordNetLemmatizer\n",
    "from nltk import sent_tokenize\n",
    "from nltk import pos_tag\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def preprocess(text):\n",
    "    # convert to ASCII\n",
    "\n",
    "    # if the input is HTML, force-add full stops after these tags\n",
    "    fullStopTags = ['li', 'p', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'dd']\n",
    "    for tag in fullStopTags:\n",
    "        text = re.sub(r'</'+tag+'>', '.', text)\n",
    "    text = re.sub(r'<[^>]+>', '', text)                  # strip out HTML\n",
    "    text = re.sub(r'[,:;()\\-]', ' ', text)               # replace commas, hyphens etc (count as spaces)\n",
    "    text = re.sub(r'[\\.!?]', '.', text)                  # unify terminators\n",
    "    text = re.sub(r'^\\s+', '', text)                     # strip leading whitespace\n",
    "    text = re.sub(r'[ ]*(\\n|\\r\\n|\\r)[ ]*', ' ', text)    # replace new lines with spaces\n",
    "    text = re.sub(r'([\\.])[\\. ]+', '.', text)            # check for duplicated terminators\n",
    "    text = re.sub(r'[ ]*([\\.])', '. ', text)             # pad sentence terminators\n",
    "    text = re.sub(r'\\s+', ' ', text)                     # remove multiple spaces\n",
    "    text = re.sub(r'\\s+$', '', text);                    # strip trailing whitespace\n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def identity(arg):\n",
    "    \"\"\"\n",
    "    Simple identity function works as a passthrough.\n",
    "    \"\"\"\n",
    "    return arg\n",
    "\n",
    "\n",
    "class NLTKPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transforms input data by using NLTK tokenization, lemmatization, and\n",
    "    other normalization and filtering techniques.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, stopwords=None, punct=None, lower=True, strip=True):\n",
    "        \"\"\"\n",
    "        Instantiates the preprocessor, which make load corpora, models, or do\n",
    "        other time-intenstive NLTK data loading.\n",
    "        \"\"\"\n",
    "        self.lower      = lower\n",
    "        self.strip      = strip\n",
    "        self.stopwords  = set(stopwords) if stopwords else set(sw.words('english'))\n",
    "        self.punct      = set(punct) if punct else set(string.punctuation)\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Fit simply returns self, no other information is needed.\n",
    "        \"\"\"\n",
    "        return self\n",
    "\n",
    "    def inverse_transform(self, X):\n",
    "        \"\"\"\n",
    "        No inverse transformation\n",
    "        \"\"\"\n",
    "        return X\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Actually runs the preprocessing on each document.\n",
    "        \"\"\"\n",
    "        return [\n",
    "            list(self.tokenize(doc)) for doc in X\n",
    "        ]\n",
    "\n",
    "    def tokenize(self, document):\n",
    "        \"\"\"\n",
    "        Returns a normalized, lemmatized list of tokens from a document by\n",
    "        applying segmentation (breaking into sentences), then word/punctuation\n",
    "        tokenization, and finally part of speech tagging. It uses the part of\n",
    "        speech tags to look up the lemma in WordNet, and returns the lowercase\n",
    "        version of all the words, removing stopwords and punctuation.\n",
    "        \"\"\"\n",
    "        # Break the document into sentences\n",
    "        for sent in sent_tokenize(document):\n",
    "            # Break the sentence into part of speech tagged tokens\n",
    "            for token, tag in pos_tag(wordpunct_tokenize(sent)):\n",
    "                # Apply preprocessing to the token\n",
    "                token = token.lower() if self.lower else token\n",
    "                token = token.strip() if self.strip else token\n",
    "                token = token.strip('_') if self.strip else token\n",
    "                token = token.strip('*') if self.strip else token\n",
    "\n",
    "                # If punctuation or stopword, ignore token and continue\n",
    "                if token in self.stopwords or all(char in self.punct for char in token):\n",
    "                    continue\n",
    "\n",
    "                # Lemmatize the token and yield\n",
    "                lemma = self.lemmatize(token, tag)\n",
    "                yield lemma\n",
    "\n",
    "    def lemmatize(self, token, tag):\n",
    "        \"\"\"\n",
    "        Converts the Penn Treebank tag to a WordNet POS tag, then uses that\n",
    "        tag to perform much more accurate WordNet lemmatization.\n",
    "        \"\"\"\n",
    "        tag = {\n",
    "            'N': wn.NOUN,\n",
    "            'V': wn.VERB,\n",
    "            'R': wn.ADV,\n",
    "            'J': wn.ADJ\n",
    "        }.get(tag[0], wn.NOUN)\n",
    "\n",
    "        return self.lemmatizer.lemmatize(token, tag)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.replace(\"<br />\", \" \")\n",
    "    text = text.decode(\"utf-8\")\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def edgemap(input):\n",
    "\n",
    "    if float(input) > 0.5:\n",
    "        sentiment = 1\n",
    "    else:\n",
    "        sentiment = 0\n",
    "\n",
    "    return pd.Series(dict(sentiment=sentiment))\n",
    "\n",
    "\n",
    "def VADERizer(input):\n",
    "    score = vader.polarity_scores(str(input))\n",
    "    compscore = score['compound']\n",
    "\n",
    "\n",
    "    #return pd.Series(dict(vader=1)) if compscore > 0.1 else pd.Series(dict(vader=0))\n",
    "    return pd.Series(dict(vader=1)) if (score['pos'] - 0.15 > score['neg']) else pd.Series(dict(vader=0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NeuralNetwork_clf = Pipeline([\n",
    "\n",
    "\n",
    "    ('vectorizer', CountVectorizer(analyzer=\"word\",\n",
    "                                   ngram_range=(1, 3),\n",
    "                                   tokenizer=word_tokenize,         # ! Comment line to include mark_negation and uncomment next line\n",
    "                                   #tokenizer=lambda text: mark_negation(word_tokenize(text)),\n",
    "                                   #preprocessor=lambda text: text.replace(\"<br />\", \" \"),\n",
    "                                   max_features=25000)),\n",
    "\n",
    "    ('classifier', MLPClassifier(learning_rate_init=0.01,\n",
    "                    hidden_layer_sizes=10, max_iter=100, activation='tanh', verbose=100,\n",
    "                    early_stopping=True, validation_fraction=0.05, alpha=1e-10)\n",
    "\n",
    "     )\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1754, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>Thank you for being open and for taking the ti...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>Really useful to hear everyone's questions. Ho...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1729</th>\n",
       "      <td>Lots of transformations all over the place. I ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1730</th>\n",
       "      <td>Exciting times ahead</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1733</th>\n",
       "      <td>I mentioned to X that it would be if we could ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1736</th>\n",
       "      <td>Thanks to all for an interesting session</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1737</th>\n",
       "      <td>Keep these staff talks going</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741</th>\n",
       "      <td>Presentations and timings all good.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1745</th>\n",
       "      <td>An inspiring talk from all speakers.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749</th>\n",
       "      <td>All four were great speakers - it was great to...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1751</th>\n",
       "      <td>I'd like to congratulate all the presenters on...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753</th>\n",
       "      <td>It was good to see all leadership team represe...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  sentiment  flag\n",
       "1723  Thank you for being open and for taking the ti...          1     0\n",
       "1726  Really useful to hear everyone's questions. Ho...          1     0\n",
       "1729  Lots of transformations all over the place. I ...          0     0\n",
       "1730                               Exciting times ahead          1     0\n",
       "1733  I mentioned to X that it would be if we could ...          0     0\n",
       "1736           Thanks to all for an interesting session          1     0\n",
       "1737                       Keep these staff talks going          1     0\n",
       "1741                Presentations and timings all good.          1     0\n",
       "1745               An inspiring talk from all speakers.          1     0\n",
       "1749  All four were great speakers - it was great to...          1     0\n",
       "1751  I'd like to congratulate all the presenters on...          1     0\n",
       "1753  It was good to see all leadership team represe...          1     0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('ST.csv',encoding = 'latin1')\n",
    "df1 = df1.dropna()\n",
    "df2 = pd.read_csv('Apr17stafftalks.csv',encoding = 'latin1')\n",
    "df2 = df2[df2[\"Text\"] != '']\n",
    "df2 = df2.dropna()\n",
    "df3 = pd.read_csv('July17stafftalks.csv',encoding = 'latin1')\n",
    "df = pd.concat([df1, df2,df3], ignore_index=True)\n",
    "print(df.shape)\n",
    "#delete empty \"-\" lines\n",
    "df = df[df['Text'] != \"-\"]\n",
    "df = df.dropna()\n",
    "# map from -1 to 1  -> 0 to 1\n",
    "df[\"valence\"] = ((df[\"Positive\"] - df[\"Negative\"])+1)/2.0\n",
    "\n",
    "df[\"sentiment\"] = df[\"valence\"].apply(lambda x:edgemap(x))\n",
    "\n",
    "df=df.drop(['Positive','Negative','valence'], axis=1)\n",
    "df['flag'] = 0\n",
    "df.tail(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldf1 = pd.read_csv('labeledTrainData.tsv',encoding = 'latin1',sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Text</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24988</th>\n",
       "      <td>1</td>\n",
       "      <td>While originally reluctant to jump on the band...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24989</th>\n",
       "      <td>1</td>\n",
       "      <td>I heard about this movie when watching VH1's \\...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24990</th>\n",
       "      <td>1</td>\n",
       "      <td>I've never been huge on IMAX films. They're co...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24991</th>\n",
       "      <td>0</td>\n",
       "      <td>Steve McQueen has certainly a lot of loyal fan...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24992</th>\n",
       "      <td>0</td>\n",
       "      <td>Sometimes you wonder how some people get fundi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24993</th>\n",
       "      <td>0</td>\n",
       "      <td>I am a student of film, and have been for seve...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24994</th>\n",
       "      <td>0</td>\n",
       "      <td>Unimaginably stupid, redundant and humiliating...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>0</td>\n",
       "      <td>It seems like more consideration has gone into...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>0</td>\n",
       "      <td>I don't believe they made this film. Completel...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>0</td>\n",
       "      <td>Guy is a loser. Can't get girls, needs to buil...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>0</td>\n",
       "      <td>This 30 minute documentary BuÃ±uel made in the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>1</td>\n",
       "      <td>I saw this movie as a child and it broke my he...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment                                               Text  flag\n",
       "24988          1  While originally reluctant to jump on the band...     1\n",
       "24989          1  I heard about this movie when watching VH1's \\...     1\n",
       "24990          1  I've never been huge on IMAX films. They're co...     1\n",
       "24991          0  Steve McQueen has certainly a lot of loyal fan...     1\n",
       "24992          0  Sometimes you wonder how some people get fundi...     1\n",
       "24993          0  I am a student of film, and have been for seve...     1\n",
       "24994          0  Unimaginably stupid, redundant and humiliating...     1\n",
       "24995          0  It seems like more consideration has gone into...     1\n",
       "24996          0  I don't believe they made this film. Completel...     1\n",
       "24997          0  Guy is a loser. Can't get girls, needs to buil...     1\n",
       "24998          0  This 30 minute documentary BuÃ±uel made in the...     1\n",
       "24999          1  I saw this movie as a child and it broke my he...     1"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldf1=ldf1.drop('id', axis=1)\n",
    "list(ldf1)\n",
    "ldf1.columns=['sentiment','Text']\n",
    "ldf1['flag']=1\n",
    "ldf1.tail(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf = pd.concat([df, ldf1], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>flag</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26256</th>\n",
       "      <td>It seems like more consideration has gone into...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26257</th>\n",
       "      <td>I don't believe they made this film. Completel...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26258</th>\n",
       "      <td>Guy is a loser. Can't get girls, needs to buil...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26259</th>\n",
       "      <td>This 30 minute documentary BuÃ±uel made in the...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26260</th>\n",
       "      <td>I saw this movie as a child and it broke my he...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  flag  sentiment\n",
       "26256  It seems like more consideration has gone into...     1          0\n",
       "26257  I don't believe they made this film. Completel...     1          0\n",
       "26258  Guy is a loser. Can't get girls, needs to buil...     1          0\n",
       "26259  This 30 minute documentary BuÃ±uel made in the...     1          0\n",
       "26260  I saw this movie as a child and it broke my he...     1          1"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdf.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "#X=fdf['Text'].values.astype('U')\n",
    "#y=fdf[\"sentiment\"].values\n",
    "\n",
    "#train_X, test_X, train_y, test_y = train_test_split(X,y, test_size=0.1, random_state=0)\n",
    "\n",
    "\n",
    "train_X = fdf['Text'].values[500:]\n",
    "test_X = fdf['Text'].values[:500]\n",
    "\n",
    "\n",
    "train_y = fdf['sentiment'].values[500:]\n",
    "test_y = fdf['sentiment'].values[:500]\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- NeuralNetwork Classifier ---------- \n",
      "Iteration 1, loss = 0.41797730\n",
      "Validation score: 0.885758\n",
      "Iteration 2, loss = 0.19172023\n",
      "Validation score: 0.890327\n",
      "Iteration 3, loss = 0.13063656\n",
      "Validation score: 0.889566\n",
      "Iteration 4, loss = 0.10091339\n",
      "Validation score: 0.881950\n",
      "Iteration 5, loss = 0.08508719\n",
      "Validation score: 0.898705\n",
      "Iteration 6, loss = 0.06193375\n",
      "Validation score: 0.889566\n",
      "Iteration 7, loss = 0.05354168\n",
      "Validation score: 0.885758\n",
      "Iteration 8, loss = 0.04259026\n",
      "Validation score: 0.890327\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Pipeline(memory=None,\n",
      "     steps=[('vectorizer', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=25000, min_df=1,\n",
      "        ngram_range=(1, 3), preprocessor=None, stop_words=None,\n",
      "      ...e=True, solver='adam', tol=0.0001, validation_fraction=0.05,\n",
      "       verbose=100, warm_start=False))])\n",
      "1.0\n",
      "Iteration 1, loss = 0.33747955\n",
      "Validation score: 0.904399\n",
      "Iteration 2, loss = 0.14627638\n",
      "Validation score: 0.890863\n",
      "Iteration 3, loss = 0.09272478\n",
      "Validation score: 0.893401\n",
      "Iteration 4, loss = 0.06360056\n",
      "Validation score: 0.898477\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.47680293\n",
      "Validation score: 0.879865\n",
      "Iteration 2, loss = 0.20234976\n",
      "Validation score: 0.885787\n",
      "Iteration 3, loss = 0.12837473\n",
      "Validation score: 0.876481\n",
      "Iteration 4, loss = 0.08866595\n",
      "Validation score: 0.878173\n",
      "Iteration 5, loss = 0.06599618\n",
      "Validation score: 0.877327\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.35306001\n",
      "Validation score: 0.890017\n",
      "Iteration 2, loss = 0.16760254\n",
      "Validation score: 0.884941\n",
      "Iteration 3, loss = 0.11594688\n",
      "Validation score: 0.896785\n",
      "Iteration 4, loss = 0.08116159\n",
      "Validation score: 0.892555\n",
      "Iteration 5, loss = 0.06785712\n",
      "Validation score: 0.877327\n",
      "Iteration 6, loss = 0.05534109\n",
      "Validation score: 0.880711\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.39493519\n",
      "Validation score: 0.895093\n",
      "Iteration 2, loss = 0.17276768\n",
      "Validation score: 0.898477\n",
      "Iteration 3, loss = 0.10838615\n",
      "Validation score: 0.893401\n",
      "Iteration 4, loss = 0.08081140\n",
      "Validation score: 0.888325\n",
      "Iteration 5, loss = 0.06675862\n",
      "Validation score: 0.895093\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.41395879\n",
      "Validation score: 0.877327\n",
      "Iteration 2, loss = 0.18503761\n",
      "Validation score: 0.876481\n",
      "Iteration 3, loss = 0.11913415\n",
      "Validation score: 0.868020\n",
      "Iteration 4, loss = 0.08484370\n",
      "Validation score: 0.874788\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.44974605\n",
      "Validation score: 0.888325\n",
      "Iteration 2, loss = 0.19156071\n",
      "Validation score: 0.886633\n",
      "Iteration 3, loss = 0.12383936\n",
      "Validation score: 0.895093\n",
      "Iteration 4, loss = 0.09067208\n",
      "Validation score: 0.894247\n",
      "Iteration 5, loss = 0.06687423\n",
      "Validation score: 0.885787\n",
      "Iteration 6, loss = 0.04862862\n",
      "Validation score: 0.890863\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.38770471\n",
      "Validation score: 0.865482\n",
      "Iteration 2, loss = 0.17821810\n",
      "Validation score: 0.863790\n",
      "Iteration 3, loss = 0.11577120\n",
      "Validation score: 0.872250\n",
      "Iteration 4, loss = 0.08662775\n",
      "Validation score: 0.869712\n",
      "Iteration 5, loss = 0.06679459\n",
      "Validation score: 0.872250\n",
      "Iteration 6, loss = 0.05942347\n",
      "Validation score: 0.868020\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.38626243\n",
      "Validation score: 0.872250\n",
      "Iteration 2, loss = 0.17825152\n",
      "Validation score: 0.872250\n",
      "Iteration 3, loss = 0.11550371\n",
      "Validation score: 0.862944\n",
      "Iteration 4, loss = 0.08283441\n",
      "Validation score: 0.868866\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.39221936\n",
      "Validation score: 0.878173\n",
      "Iteration 2, loss = 0.18120398\n",
      "Validation score: 0.881557\n",
      "Iteration 3, loss = 0.11373517\n",
      "Validation score: 0.877327\n",
      "Iteration 4, loss = 0.07990763\n",
      "Validation score: 0.879019\n",
      "Iteration 5, loss = 0.05755665\n",
      "Validation score: 0.892555\n",
      "Iteration 6, loss = 0.04836132\n",
      "Validation score: 0.894247\n",
      "Iteration 7, loss = 0.03931392\n",
      "Validation score: 0.882403\n",
      "Iteration 8, loss = 0.03475319\n",
      "Validation score: 0.887479\n",
      "Iteration 9, loss = 0.02899333\n",
      "Validation score: 0.885787\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.37703848\n",
      "Validation score: 0.867174\n",
      "Iteration 2, loss = 0.17123251\n",
      "Validation score: 0.872250\n",
      "Iteration 3, loss = 0.11573518\n",
      "Validation score: 0.883249\n",
      "Iteration 4, loss = 0.08135496\n",
      "Validation score: 0.876481\n",
      "Iteration 5, loss = 0.05999785\n",
      "Validation score: 0.879865\n",
      "Iteration 6, loss = 0.04707587\n",
      "Validation score: 0.878173\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "[0.72440046 0.89151123 0.8960396  0.88690023 0.88918507 0.88766184\n",
      " 0.88956588 0.89756283 0.88728104 0.87961905]\n",
      "0.8729727230526002\n"
     ]
    }
   ],
   "source": [
    "print(\"---------- NeuralNetwork Classifier ---------- \")\n",
    "print(NeuralNetwork_clf.fit(train_X, train_y))\n",
    "print(NeuralNetwork_clf.score(test_X, test_y))\n",
    "\n",
    "scores = cross_val_score(NeuralNetwork_clf, X, y, cv=10)\n",
    "print (scores)\n",
    "print (np.mean(scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['StaffTalksCLF.pkl']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0.84 NOT BAD! LETS PICKLE THIS CLASSIFIER\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(NeuralNetwork_clf, 'StaffTalksCLF.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "\n",
    "hmd=pd.read_csv('sdemo.csv',encoding = 'latin1')\n",
    "\n",
    "\n",
    "\n",
    "Y_pred = NeuralNetwork_clf.predict(hmd.Text.values)\n",
    "\n",
    "Y_pred_prob = NeuralNetwork_clf.predict_proba(hmd.Text.values)[:,1]\n",
    "Pred_output_dataframe = pd.DataFrame({'Text':hmd.Text.values,'Y_pred':Y_pred,'Y_pred_prob':Y_pred_prob})\n",
    "\n",
    "Pred_output_dataframe['Lexicon'] = Pred_output_dataframe.Text.apply(lambda x:VADERizer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Y_pred</th>\n",
       "      <th>Y_pred_prob</th>\n",
       "      <th>Lexicon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i dont think i like this stuff</td>\n",
       "      <td>0</td>\n",
       "      <td>0.476629</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>more change is needed</td>\n",
       "      <td>0</td>\n",
       "      <td>0.045460</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>under this law you are terminated</td>\n",
       "      <td>0</td>\n",
       "      <td>0.135778</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is great</td>\n",
       "      <td>1</td>\n",
       "      <td>0.988882</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I like the fact that I learn a lot</td>\n",
       "      <td>1</td>\n",
       "      <td>0.782660</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The ONS is the best</td>\n",
       "      <td>1</td>\n",
       "      <td>0.995220</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Text  Y_pred  Y_pred_prob  Lexicon\n",
       "0      i dont think i like this stuff       0     0.476629        0\n",
       "1               more change is needed       0     0.045460        0\n",
       "2   under this law you are terminated       0     0.135778        0\n",
       "3                       This is great       1     0.988882        1\n",
       "4  I like the fact that I learn a lot       1     0.782660        1\n",
       "5                 The ONS is the best       1     0.995220        1"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pred_output_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
